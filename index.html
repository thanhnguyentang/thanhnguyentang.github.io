<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
</td>
<td id="layout-content">
<table class="imgtable"><tr><td>
<img src="figure/tnt_25.png" alt="alt text" width="160px" height="180px" />&nbsp;</td>
<td align="left"><p><b>Thanh Nguyen-Tang</b> (TNT) <br />
Assistant Professor<br />
<a href="https://ds.njit.edu/" target=&ldquo;blank&rdquo;>Department of Data Science</a> <br /> 
<a href="https://computing.njit.edu/" target=&ldquo;blank&rdquo;>Ying Wu College of Computing</a> <br />
New Jersey Institute of Technology<br />
218 Central Ave <br /> 
GITC 2110 <br /> 
Newark, NJ 07102 <br /> 
<i>thanh.nguyen</i> at njit dot edu | <i>thnguyentang</i> at gmail dot com <br />
<a href="https://scholar.google.com/citations?hl=en&amp;user=UrTlMiwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target=&ldquo;blank&rdquo;>Google Scholar</a>
</p>
</td></tr></table>
<p><b>Bio</b>: I am an assistant professor in the Department of Data Science, Ying Wu College of Computing at New Jersey Institute of Technology (NJIT). 
Prior to that, I was a postdoc at Johns Hopkins University (with <a href="https://www.cs.jhu.edu/~raman/Home.html" target=&ldquo;blank&rdquo;>Raman Arora</a>),
did my PhD in Computer Science at Deakin University, Australia,  
my M.Sc. in Computer Science and Engineering at Ulsan National Institute of Science and Technology, South Korea, 
my B.Eng. in Electronic and Communication Engineering (Talented Engineering Program) at Danang University of Science and Technology, Vietnam. I was awarded the Alfred Deakin Medal for Doctoral Theses, 2022.
</p>
<p><b>Research Interest</b>: I am mostly interested in the theoretical and algorithmic aspects of machine learning motivated by real-world problem settings. 
I like to seek a mathematical understanding of the underlying algorithmic principles for learning with strong adaptivity to problem structures, and thereby design efficient machine learning algorithms with strong theoretical guarantees. 
The current topics include, but not limited to, Reinforcement Learning (e.g., Offline RL, Multi-agent, Multi-task), Understanding Inductive Bias for Reasoning in LLMs (e.g., optimization and architectural bias), and 
responsible AI (e.g., privacy, robustness, unlearning). 
</p>
<p><b>Open positions</b>: I am seeking highly motivated and self-driven Ph.D. students with a strong mathematical background in machine learning to join my research group at the Ying Wu College of Computing at NJIT, starting in Spring or Fall 2026. We are working on the statistical and algorithmic theory of RL, transformers and responsible AI.
<b>How to apply:</b> Apply directly to the DS PhD program at NJIT and mention my name. <b>Note:</b> <i>When applying, you are also strongly encouraged to email me with your CV, transcript, and a brief paragraph describing research experience and areas of interest. Due to a large volume of emails I receive, I may not be able to respond to every individual application email - but rest assured that I read each one of them.</i>
</p>
<p>*<i>Undergrads/Masters students who are interested in doing research in the theory of RL/transformers/responsible AI with me, can email me.</i>
</p>
<p><b>Service</b>: Area Chair at NeurIPS (2025), AISTATS (2026, 2025), AAMAS (2026); Senior Program Committee at AAAI (2026, 2025, 2024, 2023).
</p>
<p><b>Teaching</b>:  
CS 669 (Reinforcement Learning), NJIT, Fall 2025; Machine Learning: Advanced Topics (EN.601.779.01.SP24), JHU CS, Spring 2024.
</p>
<p><b>Publications</b>: 
</p>
<ul>
<li><p>Yassine Chemingui, Aryan Deshwal, Alan Fern, <u>Thanh Nguyen-Tang</u>, Jana Doppa. 
<i><b>O3SRL: Online Optimization for Offline Safe Reinforcement Learning</b></i>. <font color=red ><b>NeurIPS</b></font>, 2025.
</p>
</li>
<li><p>Ragja Palakkadavath, Hung Le, <u>Thanh Nguyen-Tang</u>, Svetha Venkatesh, and Sunil Gupta. 
<i><b>Federated Domain Generalization with Latent Space Inversion</b></i>. <font color=red ><b>ICDM</b></font>, 2025.
</p>
</li>
<li><p>Khai Le-Duc, Tuyen Tran, Bach Phan Tat, Nguyen Kim Hai Bui, Quan Dang, Hung-Phong Tran, Thanh-Thuy Nguyen, Ly Nguyen, Tuan-Minh Phan, Thi Thu Phuong Tran, Chris Ngo, Nguyen X Khanh, <u>Thanh Nguyen-Tang</u>. 
<i><b>MultiMed-ST: Large-scale Many-to-many Multilingual Medical Speech Translation</b></i>. <font color=red ><b>EMNLP</b></font>, 2025. [<a href="https://arxiv.org/pdf/2504.03546" target=&ldquo;blank&rdquo;>arXiv</a>]
</p>
</li>
<li><p>Khai Le-Duc, Phuc Phan, Tan-Hanh Pham, Bach Phan Tat, Minh-Huong Ngo, <u>Thanh Nguyen-Tang</u>, Truong-Son Hy. <i><b>MultiMed: Multilingual medical speech recognition via attention encoder decoder</b></i>.  <font color=red ><b>ACL (Industry)</b></font>, 2025. [<a href="https://arxiv.org/pdf/2409.14074v3" target=&ldquo;blank&rdquo;>pdf</a>]
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Raman Arora. <i><b>Policy regret minimization in Markov games with function approximation</b></i>. <font color=red ><b>ICML</b></font>, 2025.
</p>
</li>
<li><p>Anh Tong, <u>Thanh Nguyen-Tang</u>, Dongeun Lee, Duc Nguyen, Toan Tran, David Leo Wright Hall, Cheongwoong Kang, Jaesik Choi. 
<i><b>Neural ODE transformers: Analyzing internal dynamics and adaptive fine-tuning</b></i>. <font color=red ><b>ICLR</b></font>, 2025.
</p>
</li>
<li><p>Nguyen Hung-Quang, Ngoc-Hieu Nguyen, The-Anh Ta, <u>Thanh Nguyen-Tang</u>, Kok-Seng Wong, Hoang Thanh-Tung,
and Khoa D Doan. <i><b>Wicked oddities: Selectively poisoning for effective clean-label backdoor attacks</b></i>. <font color=red ><b>ICLR</b></font>, 2025 [<a href="https://arxiv.org/pdf/2407.10825" target=&ldquo;blank&rdquo;>pdf</a>]. 
</p>
</li>
<li><p>Ragja Palakkadavath, Hung Le, <u>Thanh Nguyen-Tang</u>, Svetha Venkatesh, Sunil Gupta. 
<i><b>Fair domain generalization with heterogeneous sensitive attributes across domains</b></i>. <font color=red ><b>WACV</b></font>, 2025 [<a href="https://openreview.net/pdf?id=3wL1tj3kqE" target=&ldquo;blank&rdquo;>pdf</a>].
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Raman Arora. <i><b>Learning in Markov games with adaptive adversaries: Policy regret, fundamental barriers, and efficient algorithms</b></i>. <font color=red ><b>NeurIPS</b></font>, 2024 [<a href="https://arxiv.org/pdf/2411.00707" target=&ldquo;blank&rdquo;>pdf</a>]. 
</p>
</li>
<li><p>Austin Watkins, <u>Thanh Nguyen-Tang</u>, Enayat Ullah, Raman Arora. <i><b>Adversarially robust multi-task representation learning</b></i>. <font color=red ><b>NeurIPS</b></font>, 2024 [<a href="https://openreview.net/pdf?id=w2L3Ll1jbV" target=&ldquo;blank&rdquo;>pdf</a>]. 
</p>
</li>
<li><p>Haque Ishfaq, <u>Thanh Nguyen-Tang</u>, Songtao Feng, Raman Arora, Mengdi Wang, Ming Yin, Doina Precup. <i><b>Offline multitask representation learning for reinforcement learning</b></i>. <font color=red ><b>NeurIPS</b></font>, 2024 [<a href="https://arxiv.org/pdf/2403.11574" target=&ldquo;blank&rdquo;>pdf</a>].
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Raman Arora. <i><b>On the statistical complexity of offline decision-making</b></i>. <font color=red ><b>ICML</b></font>, 2024 [<a href="https://openreview.net/pdf?id=dYDPcx78tm" target=&ldquo;blank&rdquo;>pdf</a>]. 
</p>
</li>
<li><p>Anh Tong, <u>Thanh Nguyen-Tang</u>, Dongeun Lee, Toan Tran, Jaesik Choi. <i><b>SigFormer: Signature transformers for deep hedging</b></i>. <font color=red ><b>ICAIF</b></font>, 2023 (<font color=red >Oral</font>)[<a href="https://arxiv.org/abs/2310.13369" target=&ldquo;blank&rdquo;>pdf]</a>. <br /> 
</p>
</li>
<li><p>Anh Do, <u>Thanh Nguyen-Tang</u>, Raman Arora. <i><b>Multi-agent learning with heterogeneous linear contextual bandits</b></i>. <font color=red ><b>NeurIPS</b></font>, 2023 [<a href="[https://openreview.net/forum?id=7f6vH3mmhr" target=&ldquo;blank&rdquo;>pdf</a>]. <br />
</p>
</li>
<li><p>Austin Watkins, Enayat Ullah, <u>Thanh Nguyen-Tang</u>, Raman Arora. <i><b>Optimistic rates for multi-task representation learning</b></i>. <font color=red ><b>NeurIPS</b></font>, 2023 [<a href="https://openreview.net/forum?id=gQ4h6WvME0" target=&ldquo;blank&rdquo;>pdf</a>]<br />
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Raman Arora. <i><b>On sample-efficient offline reinforcement learning: Data diversity, posterior sampling and beyond</b></i>. <font color=red ><b>NeurIPS</b></font>, 2023 [<a href="https://openreview.net/forum?id=sdlh4gVOj8" target=&ldquo;blank&rdquo;>pdf</a>]. <br />
</p>
</li>
<li><p>Ragja Palakkadavath, <u>Thanh Nguyen-Tang</u>, Hung Le, Svetha Venkatesh, Sunil Gupta.  <i><b>Domain generalization with interpolation robustness</b></i>. <font color=red ><b>ACML</b></font>, 2023 [<a href="https://openreview.net/pdf?id=Yl_4LpR_3Z" target=&ldquo;blank&rdquo;>pdf</a>]. <br />
</p>
</li>
<li><p>Thong Bach, Anh Tong, Truong Son Hy, Vu Nguyen, <u>Thanh Nguyen-Tang</u>. <i><b>Global contrastive learning for long-tailed classification</b></i>. <font color=red ><b>TMLR</b></font>, 2023 [<a href="https://openreview.net/forum?id=xWrtiJwJj5" target=&ldquo;blank&rdquo;>pdf</a>]. <br />
</p>
</li>
<li><p>A. Tuan Nguyen, <u>Thanh Nguyen-Tang</u>, Ser-Nam Lim, Philip Torr. <i><b>TIPI: Test time adaptation with transformation invariance</b></i>. <font color=red ><b>CVPR</b></font>, 2023 [<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Nguyen_TIPI_Test_Time_Adaptation_With_Transformation_Invariance_CVPR_2023_paper.html" target=&ldquo;blank&rdquo;>html</a>].  <br />
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Raman Arora. <i><b>VIPeR: Provably efficient algorithm for offline RL with neural function approximation</b></i>. <font color=red ><b>ICLR</b></font>, 2023 (<font color=red >top 25% noble</font>).
[<a href="https://recorder-v3.slideslive.com/?share=80688&amp;s=a24d555f-edda-4210-a19e-4fded4165c62" target=&ldquo;blank&rdquo;>talk</a>] [<a href="assets/viper.pdf" target=&ldquo;blank&rdquo;>slides</a>] [<a href="https://github.com/thanhnguyentang/neural-offline-rl" target=&ldquo;blank&rdquo;>code</a>]  [<a href="notes/erratumiclr23.html" target=&ldquo;blank&rdquo;><b>ERRATUM</b></a>.] <br />
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Ming Yin, Sunil Gupta, Svetha Venkatesh, Raman Arora. <i><b>On instance-dependent bounds for offline reinforcement learning with linear function approximation</b></i>. <font color=red ><b>AAAI</b></font>, 2023 [<a href="https://arxiv.org/abs/2211.13208" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="assets/aaai23-poster.pdf" target=&ldquo;blank&rdquo;>poster</a>] [<a href="assets/aaai23-slides-only.pdf" target=&ldquo;blank&rdquo;>slides</a>] [<a href="https://youtu.be/xUsMHodydO8" target=&ldquo;blank&rdquo;>video</a>].
</p>
</li>
<li><p>Anh Tong, <u>Thanh Nguyen-Tang</u>, Toan Tran, Jaesik Choi. <i><b>Learning fractional white noises in neural stochastic differential equations</b></i>. <font color=red ><b>NeurIPS</b></font>, 2022 [<a href="https://openreview.net/pdf?id=lTZBRxm2q5" target=&ldquo;blank&rdquo;>pdf</a>] 
[<a href="https://github.com/anh-tong/fractional_neural_sde" target=&ldquo;blank&rdquo;>code</a>]. 
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Sunil Gupta, A.Tuan Nguyen, and Svetha Venkatesh. <i><b>Offline neural contextual bandits:  Pessimism, optimization, and generalization</b></i>. <font color=red ><b>ICLR</b></font>, 2022 [<a href="https://openreview.net/pdf?id=sPIFuucA3F" target=&ldquo;blank&rdquo;>pdf</a>] [<a href="assets/poster_NeurIPSW21.pdf" target=&ldquo;blank&rdquo;>poster</a>]  
[<a href="assets/neuralcb_slides.pdf" target=&ldquo;blank&rdquo;>slides</a>] 
[<a href="https://github.com/thanhnguyentang/offline_neural_bandits" target=&ldquo;blank&rdquo;>code</a>].
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Sunil Gupta, Hung Tran-The, Svetha Venkatesh. <i><b>On sample complexity of offline reinforcement learning with deep ReLU networks in Besov spaces</b></i>. <font color=red ><b>TMLR</b></font>, 2022, Workshop on RL Theory, ICML, 2021 [<a href="https://arxiv.org/abs/2103.06671" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://thanhnguyentang.github.io/assets/offrelu.pdf" target=&ldquo;blank&rdquo;>slides</a>] 
[<a href="https://www.youtube.com/watch?v=xLM5pondWY4" target=&ldquo;blank&rdquo;>talk</a>].
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Sunil Gupta, Svetha Venkatesh. <i><b>Distributional reinforcement learning via moment matching</b></i>. <font color=red ><b>AAAI</b></font>, 2021 [<a href="http://arxiv.org/abs/2007.12354" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://github.com/thanhnguyentang/mmdrl" target=&ldquo;blank&rdquo;>code</a>]
[<a href="https://cutt.ly/fkkiAGm" target=&ldquo;blank&rdquo;>slides</a>] 
[<a href="https://cutt.ly/4kkiJZt" target=&ldquo;blank&rdquo;>poster</a>] [<a href="https://youtu.be/1fMqZZjy84E" target=&ldquo;blank&rdquo;>talk</a>].  
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Sunil Gupta, Huong Ha, Santu Rana, Svetha Venkatesh. <i><b>Distributionally robust Bayesian quadrature optimization</b></i>. <font color=red ><b>AISTATS</b></font>, 2020 [<a href="https://arxiv.org/abs/2001.06814" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://github.com/thanhnguyentang/drbqo" target=&ldquo;blank&rdquo;>code</a>]
[<a href="https://thanhnguyentang.github.io/assets/aistats20_drbqo.pdf" target=&ldquo;blank&rdquo;>slides</a>] 
[<a href="https://slideslive.com/38930124/" target=&ldquo;blank&rdquo;>talk</a>].  
</p>
</li>
<li><p>Huong Ha, Santu Rana, Sunil Gupta, <u>Thanh Nguyen-Tang</u>, Hung Tran-The, Svetha Venkatesh. <i><b>Bayesian optimization with unknown search space</b></i>. <font color=red ><b>NeurIPS</b></font>, 2019 [<a href="https://papers.nips.cc/paper/9350-bayesian-optimization-with-unknown-search-space" target=&ldquo;blank&rdquo;>pdf</a>] [<a href="https://github.com/HuongHa12/BO_unknown_searchspace" target=&ldquo;blank&rdquo;>code</a>]
[<a href="https://postersession.ai/poster/bayesian-optimization-with-unknown-searc/" target=&ldquo;blank&rdquo;>poster</a>].
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Jaesik Choi. <i><b>Markov information bottleneck to improve information flow in stochastic neural networks</b></i>. <font color=red ><b>Entropy</b></font>, 2019 (Invited, special Issue on Information Bottleneck: Theory and Applications in Deep Learning) [<a href="https://doi.org/10.3390/e21100976" target=&ldquo;blank&rdquo;>pdf</a>].   <br />
</p>
</li>
</ul>
<p><b>Preprint</b>:
</p>
<ul>
<li><p>Quan Nguyen, <u>Thanh Nguyen-Tang</u>. <i><b>One-Layer Transformers are Provably Optimal for In-context Reasoning and Distributional Association Learning in Next-Token Prediction Tasks</b></i>. [<a href="https://arxiv.org/abs/2505.15009" target=&ldquo;blank&rdquo;>ArXiv</a>]
</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
