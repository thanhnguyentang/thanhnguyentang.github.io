# jemdoc:index.html, showsource 
= Thanh Nguyen-Tang
Postdoctoral Research Fellow \n
[https://www.cs.jhu.edu/ Department of Computer Science] \n 
[https://engineering.jhu.edu/ Whiting School of Engineering] \n 
[https://www.jhu.edu/ Johns Hopkins University] \n \n
Malone Hall 331, 3400 N Charles Street, Baltimore, MD 21218 \n 
 /nguyent/ at cs dot jhu dot edu \/ /thnguyentang/ at gmail dot com \n \n 
[https://scholar.google.com/citations?hl=en&user=UrTlMiwAAAAJ&view_op=list_works&sortby=pubdate Google Scholar] \n \n
[https://terrytao.wordpress.com/career-advice/work-hard/ /Demystify modern machine learning, one idea at a time./]

== About Me  
I am a Postdoctoral Research Fellow in Department of Computer Science at Johns Hopkins University, 
working with [https://www.cs.jhu.edu/~raman/Home.html Raman Arora]. I did my PhD research in [https://a2i2.deakin.edu.au/publications/ the Applied AI Institute], Deakin University (Australia) in 2022, and did my Master research in Computer Science and Engineering at [http://sailab.kaist.ac.kr/publications/ the Statistical AI Lab], Ulsan National Institute of Science and Technology (South Korea) in 2018. 
== Research Interests   
I am interested in the Theory of Machine Learning (ML). 
My research explores how to learn as much information as possible from empirical observations, in various realistic settings and algorthmic constraints motivated by modern practice of AI and Data Science, 
and use this understanding to inform practical algorithms that are efficient and robust. I often seek answers through the lens of learning theory, statistical inference, and algorithmic information theory. 
Here are some questions I've recently working on: 
- How much information from pre-collected experiences one can learn to extract a useful behavior? What are appropriote notions of transferrability from pre-collected experiences to an useful behavior? 
- How much information one can re-use from source tasks to target tasks? 
How much information one can collaboratively share across multiple tasks to solve these tasks more quickly? 
- Can one make learning robust when the environment and/or empirical observations are partially manipulated? 
- Can one incorporate human preference as an bias into learning? Can one learn human preference out of empirical observations or interactions? 


== Publications  
=== 2023 
- Anh Tong, _Thanh Nguyen-Tang_, Dongeun Lee, Toan Tran, Jaesik Choi. [https://arxiv.org/abs/2310.13369 SigFormer: Signature Transformers for Deep Hedging]. 4th ACM International Conference on AI in Finance ({{<font color=red >}}ICAIF{{</font>}}), 2023 ({{<font color=red >}}Oral{{</font>}}). 
- Anh Do, _Thanh Nguyen-Tang_, Raman Arora.  Multi-Agent Learning with Heterogeneous Linear Contextual Bandits. Advances in Neural Information Processing Systems ({{<font color=red >}}NeurIPS{{</font>}}), 2023.
- Austin Watkins, Enayat Ullah, _Thanh Nguyen-Tang_, Raman Arora. Optimistic Rates for Multi-Task Representation Learning. Advances in Neural Information Processing Systems ({{<font color=red >}}NeurIPS{{</font>}}), 2023.
- _Thanh Nguyen-Tang_, Raman Arora. On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling and Beyond. Advances in Neural Information Processing Systems ({{<font color=red >}}NeurIPS{{</font>}}), 2023. \[[preprints/NT-neurips23.pdf pdf]\]
-  Ragja Palakkadavath, _Thanh Nguyen-Tang_, Hung Le, Svetha Venkatesh, Sunil Gupta. [https://openreview.net/pdf?id=Yl_4LpR_3Z Domain Generalization with Interpolation Robustness]. Asian Conference on Machine Learning ({{<font color=red >}}ACML{{</font>}}), 2023. 
- Thong Bach, Anh Tong, Truong Son Hy, Vu Nguyen, _Thanh Nguyen-Tang_. [https://openreview.net/forum?id=xWrtiJwJj5 Global Contrastive Learning for Long-Tailed Classification]. Transactions on Machine Learning Research ({{<font color=red >}}TMLR{{</font>}}), 2023. 
- A. Tuan Nguyen, _Thanh Nguyen-Tang_, Ser-Nam Lim, Philip Torr. [https://openaccess.thecvf.com/content/CVPR2023/html/Nguyen_TIPI_Test_Time_Adaptation_With_Transformation_Invariance_CVPR_2023_paper.html TIPI: Test Time Adaptation with Transformation Invariance]. IEEE/CVF Conference on Computer Vision and Pattern Recognition {{<font color=red >}}(CVPR){{</font>}}, 2023.  
- _Thanh Nguyen-Tang_, Raman Arora. [https://openreview.net/forum?id=WOquZTLCBO1 VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation].
    International Conference on Learning Representations ({{<font color=red >}}ICLR{{</font>}}), 2023 ({{<font color=red >}}top 25% noble{{</font>}})
     \[[https://recorder-v3.slideslive.com/?share=80688&s=a24d555f-edda-4210-a19e-4fded4165c62 talk]\] \[[assets/viper.pdf slides]\] \[[https://github.com/thanhnguyentang/neural-offline-rl code]\].  
-  _Thanh Nguyen-Tang_, Ming Yin, Sunil Gupta, Svetha Venkatesh, Raman Arora. [/home On Instance-Dependent Bounds for Offline Reinforcement Learning with Linear Function Approximation].
    AAAI Conference on Artificial Intelligence ({{<font color=red >}}AAAI{{</font>}}), 2023 \[[https://arxiv.org/abs/2211.13208 arXiv]\] \[[assets/aaai23-poster.pdf poster]\] \[[assets/aaai23-slides-only.pdf slides]\] \[[https://youtu.be/xUsMHodydO8 video]\].

=== 2022   
- _Thanh Nguyen-Tang_, Sunil Gupta, Hung Tran-The, Svetha Venkatesh. [https://openreview.net/forum?id=LdEm0umNcv On Sample Complexity of Offline Reinforcement Learning with Deep ReLU Networks in Besov Spaces]. 
    Transactions on Machine Learning Research ({{<font color=red >}}TMLR{{</font>}}), 2022.  
-  Ragja Palakkadavath, _Thanh Nguyen-Tang_, Sunil Gupta, Svetha Venkatesh. [https://openreview.net/pdf?id=Yl_4LpR_3Z Domain Generalization with Interpolation Robustness]. 
    Distribution Shifts Workshop@NeurIPS, INTERPOLATE@NeurIPS ({{<font color=red >}}Spotlight{{</font>}}), 2022.  
-  Anh Tong, _Thanh Nguyen-Tang_, Toan Tran, Jaesik Choi. [https://openreview.net/pdf?id=lTZBRxm2q5 Learning Fractional White Noises in Neural Stochastic Differential Equations].
    Advances in Neural Information Processing Systems ({{<font color=red >}}NeurIPS{{</font>}}), 2022. 
    \[[https://github.com/anh-tong/fractional_neural_sde code]\].  
- Mengyan Zhang, _Thanh Nguyen-Tang_, Fangzhao Wu, Zhenyu He, Xing Xie, Cheng Soon Ong. 
[/home Two-Stage Neural Contextual Bandits for Adaptive Personalised Recommendation]. Preprint, 2022.  
    \[[https://arxiv.org/abs/2206.14648 arXiv]\].  
- _Thanh Nguyen-Tang_, Sunil Gupta, A.Tuan Nguyen, and Svetha Venkatesh. 
    [https://openreview.net/pdf?id=sPIFuucA3F Offline Neural Contextual Bandits:  Pessimism, Optimization and Generalization].
    International Conference on Learning Representations ({{<font color=red >}}ICLR{{</font>}}), 2022. 
    \[[https://arxiv.org/abs/2111.13807 arXiv]\] 
\[[assets/poster_NeurIPSW21.pdf poster]\]  
\[[assets/neuralcb_slides.pdf slides]\] 
\[[https://github.com/thanhnguyentang/offline_neural_bandits code]\].  
=== 2021
- _Thanh Nguyen-Tang_, Sunil Gupta, Hung Tran-The, Svetha Venkatesh.
[https://lyang36.github.io/icml2021_rltheory/camera_ready/5.pdf Sample Complexity of Offline Reinforcement Learning with Deep ReLU Networks]. 
Workshop on RL Theory, ICML, 2021. \[[https://arxiv.org/abs/2103.06671 arXiv]\]
\[[https://thanhnguyentang.github.io/assets/offrelu.pdf slides]] 
\[[https://www.youtube.com/watch?v=xLM5pondWY4 talk]].  
- _Thanh Nguyen-Tang_, Sunil Gupta, Svetha Venkatesh. 
[https://ojs.aaai.org/index.php/AAAI/article/view/17104 Distributional Reinforcement Learning via Moment Matching]. 
AAAI Conference on Artificial Intelligence ({{<font color=red >}}AAAI{{</font>}}), 2021. 
    \[[http://arxiv.org/abs/2007.12354 arXiv]] \[[https://github.com/thanhnguyentang/mmdrl code]]
\[[https://cutt.ly/fkkiAGm slides]] 
\[[https://cutt.ly/4kkiJZt poster]] \[[https://youtu.be/1fMqZZjy84E talk]].  
=== 2020
- _Thanh Nguyen-Tang_, Sunil Gupta, Huong Ha, Santu Rana, Svetha Venkatesh. 
[http://proceedings.mlr.press/v108/nguyen20a.html Distributionally Robust Bayesian Quadrature Optimization]. 
International Conference on Artificial Intelligence and Statistics ({{<font color=red >}}AISTATS{{</font>}}), 2020. 
    \[[https://arxiv.org/abs/2001.06814 arXiv]] \[[https://github.com/thanhnguyentang/drbqo code]]
\[[https://thanhnguyentang.github.io/assets/aistats20_drbqo.pdf slides]] 
\[[https://slideslive.com/38930124/ talk]].  
=== 2019
- _Thanh Nguyen-Tang_, Jaesik Choi. 
[https://doi.org/10.3390/e21100976 Markov Information Bottleneck to Improve Information Flow in Stochastic Neural Networks]. {{<font color=red >}}Entropy{{</font>}}, 2019 (Special Issue on Information Bottleneck: Theory and Applications in Deep Learning). 
- Huong Ha, Santu Rana, Sunil Gupta, _Thanh Nguyen-Tang_, Hung Tran-The, Svetha Venkatesh.
[https://papers.nips.cc/paper/9350-bayesian-optimization-with-unknown-search-space Bayesian Optimization with Unknown Search Space].
    Advances in Neural Information Processing Systems ({{<font color=red >}}NeurIPS{{</font>}}), 2019.
    \[[https://github.com/HuongHa12/BO_unknown_searchspace code]]
\[[https://postersession.ai/poster/bayesian-optimization-with-unknown-searc/ poster]].  


== Selected Awards   
- Alfred Deakin Medal for Doctoral Theses (for the most outstanding theses), 2022.
  


== Professional Service  
- Senior program committee: AAAI (2023, 2024).
- Reviewer: NeurIPS (2023, 2022, 2021, 2020), ICML (2023, 2022, 2021), 
ICLR (2024, 2023, 2022, 2021- outstanding reviewer award), 
AAAI (2022, 2021-[https://aaai.org/Conferences/AAAI-21/wp-content/uploads/2021/05/AAAI-21-Program-Committee.pdf Top 25% PC], 2020), AISTATS (2021), L4DC (2022), EWRL (2022), NeurIPS Workshop on OfflineRL (2022, 2021), TPAMI. 
- Volunteer: AAAI (2023 - session chair for ML theory), ICML (2022), AutoML (2022).   

== Teaching  
- Teaching RL Theory in our JHU ML reading group, Summer/Fall 2023.  \[[rl-notes.html notes]\] 
- Guest lecturer (in bandits\/reinforcement learning): Machine Learning (CS 475\/675) Spring 2023, JHU. \[[rl-lectures.html notes]\] 
- Teaching Assistant: Statistical Machine Learning, Fall 2017, UNIST; Engineering Programming I/II, Spring 2016, UNIST; Various advanced mathematics and engineering courses, 2012-2016, Vietnam.  



== Invited Talks 
- TrustML Young Scientist Seminars, RIKEN Japan, Aug. 01, 2023 (Host: [http://www.ms.k.u-tokyo.ac.jp/sugi/ Masashi Sugiyama]) \[[https://trustmlresearch.github.io/seminar-talks/index_Thanh_Nguyen.html post]\] \[[/assets/riken23.pdf slides]\] \[[https://www.youtube.com/watch?v=Z-r2XmxLAgk video]\].
- VinAI, Vietnam, Jan. 13, 2023 \[[https://www.vinai.io/seminar-posts/provable-offline-reinforcement-learning-neural-function-approximation-randomization-and-sample-complexity/ post]\].
- FPT AI, Vietnam, Dec. 21, 2022 \[[https://www.youtube.com/watch?v=FNj8UScJmrk record]\].
- UC San Diego, USA, Dec. 8, 2022 (Host: [https://roseyu.com/ Rose Yu]).
- IAA Research Summit, Johns Hopkins University, USA, Nov. 2022 \[[assets/offrl_iaa_22.pdf slides]\].
- Ohio State University, USA, Jan. 2022 (Host: [https://sites.google.com/view/yingbinliang/home Yingbin Liang] and [http://newslab.ece.ohio-state.edu/home/ Ness Shroff]).
- Arizona State University, USA, Dec. 2021 (Host: [https://kwangsungjun.github.io/ Kwang-Sung Jun]).
- Virginia Tech, USA, Nov. 2021 (Host: [https://sites.google.com/site/thinhdoan210/home Thinh T. Doan]).



