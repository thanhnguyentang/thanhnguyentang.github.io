<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Thanh Nguyen-Tang</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div id="profile">
<img alt="tnt" src="profile_pic.jpg"
style="display:inline;margin:5px 10px 0px 0px;float:center" width="120">
</div>
<hr>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="blog.html">Blog</a></div>
<div class="menu-item"><a href="news.html">News&nbsp;and&nbsp;Events</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="photos.html">Photos</a></div>
<div class="menu-item"><a href="resources.html">Resources</a></div>
<hr>
<div id="counter">
  <script type='text/javascript'
    id='clustrmaps'
    src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=120&t=tt&d=82NHafzempW8zXlKpsMbUtpsRrG-yvVYFzxInVdWKuQ'>
    </script>
</div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Thanh Nguyen-Tang</h1>
<div id="subtitle">Postdoctoral Research Fellow <br />
<a href="https://www.cs.jhu.edu/" target=&ldquo;blank&rdquo;>Department of Computer Science</a> <br /> 
<a href="https://engineering.jhu.edu/" target=&ldquo;blank&rdquo;>Whiting School of Engineering</a> <br /> 
<a href="https://www.jhu.edu/" target=&ldquo;blank&rdquo;>Johns Hopkins University</a> <br /> 
3400 N Charles Street, Malone Hall 331, Baltimore, MD 21218 <br /> 
Email: <i>tnguy258</i> at jhu dot edu, or <i>nguyent2792</i> at gmail dot com 
</div>
</div>
<p>I am a Postdoctoral Research Fellow at Department of Computer Science, Whiting School of Engineering, Johns Hopkins University, 
working with <a href="https://www.cs.jhu.edu/~raman/Home.html" target=&ldquo;blank&rdquo;>Raman Arora</a>. I was an Associate Research Fellow at the Applied AI Institute, Deakin University in July 2021-June 2022 
and completed my PhD there in Feb 2022. I did my Master in Computer Science and Engineering at Ulsan National University of Science and Technology (UNIST) in 2018. 
</p>
<h2>Research Interests </h2>
<p>I am building toward data-efficient and trustworthy AI 
by studying three foundational pillars of modern machine learning - provable statistical efficiency, computational efficiency, and robustness. My current focus includes 
</p>
<ul>
<li><p>Reinforcement Learning 
</p>
</li>
<li><p>Learning under Distributional Shifts 
</p>
</li>
<li><p>Probabilistic Deep Learning 
</p>
</li>
<li><p>Representation Learning 
</p>
</li>
</ul>
<p>Iâ€™m always actively open to research collaborations and chat!
</p>
<p>Here are my 
<a href="https://scholar.google.com/citations?hl=en&amp;user=UrTlMiwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target=&ldquo;blank&rdquo;>Google Scholar</a>, 
<a href="https://www.semanticscholar.org/author/Thanh-Nguyen-Tang/1490490191?sort=pub-date" target=&ldquo;blank&rdquo;>Semantic Scholar</a>, 
<a href="https://github.com/thanhnguyentang" target=&ldquo;blank&rdquo;>Github</a>,
<a href="https://twitter.com/thanhnguyentang" target=&ldquo;blank&rdquo;>Twitter</a> . 
</p>
<h2>Recent News </h2>
<ul>
<li><p>Sep. 14, 2022: One paper got accepted to NeurIPS, 2022. 
</p>
</li>
<li><p>Aug. 8, 2022: I am acknowledged in Mengyan Zhang's PhD thesis. 
</p>
</li>
<li><p>Jan. 21, 2022: One paper got accepted to ICLR, 2022. 
</p>
</li>
<li><p>Oct. 25, 2021: A short version of our work has been accepted to the NeurIPS&rsquo;21 Workshop on Offline Reinforcement Learning.
</p>
</li>
<li><p>July 8, 2021: A short version of our work has been accepted to the ICML&rsquo;21 Workshop on Reinforcement Learning Theory.
</p>
</li>
<li><p>July 1, 2021: I start my postdoc at A\(^2\)I\(^2\), Deakin University after submitting my Ph.D. thesis in 24 Jun. 
</p>
</li>
<li><p>May 20, 2021: I have been accepted to the Deep Learning Theory Summer School at Princeton, acceptance rate: 180/500 = 36%.
</p>
</li>
</ul>
<h2>Publications  </h2>
<h3><b></b>2022<b></b>   </h3>
<ul>
<li><p><a href="https://thanhnguyentang.github.io/" target=&ldquo;blank&rdquo;>Improving Domain Generalization with Interpolation Robustness</a><br /> 
</p>
<ul>
<li><p>Ragja Palakkadavath, <b>Thanh Nguyen-Tang</b>, Sunil Gupta, Svetha Venkatesh <br />
</p>
</li>
<li><p>Distribution Shifts Workshop@NeurIPS2022, INTERPOLATE@NeurIPS2022<br />
</p>
</li>
<li><p>Under review, 2022 <br />
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://thanhnguyentang.github.io/" target=&ldquo;blank&rdquo;>Provably Efficient Neural Offline Reinforcement Learning via Perturbed Rewards</a><br /> 
</p>
<ul>
<li><p><b>Thanh Nguyen-Tang</b>, Raman Arora <br /> 
</p>
</li>
<li><p>Under review, 2022 <br />
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://thanhnguyentang.github.io/" target=&ldquo;blank&rdquo;>On Instance-Dependent Bounds for Offline Reinforcement Learning
with Linear Function Approximation</a><br /> 
</p>
<ul>
<li><p><b>Thanh Nguyen-Tang</b>, Ming Yin, Sunil Gupta, Svetha Venkatesh, Raman Arora <br /> 
</p>
</li>
<li><p>Under review, 2022 <br />
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://thanhnguyentang.github.io/" target=&ldquo;blank&rdquo;>Learning Fractional White Noises in Neural Stochastic Differential Equations</a><br />  
</p>
<ul>
<li><p>Anh Tong, <b>Thanh Nguyen-Tang</b>, Toan Tran, Jaesik Choi <br />
</p>
</li>
<li><p>NeurIPS, 2022 <br />
</p>
</li></ul>
</li>
<li><p><a href="https://arxiv.org/abs/2206.14648" target=&ldquo;blank&rdquo;>Two-Stage Neural Contextual Bandits for Adaptive Personalised Recommendation</a><br />  
</p>
<ul>
<li><p>Mengyan Zhang, <b>Thanh Nguyen-Tang</b>, Fangzhao Wu, Zhenyu He, Xing Xie, Cheng Soon Ong <br />
</p>
</li>
<li><p>Under review, 2022 <br /> 
</p>
</li>
<li><p>[<a href="https://arxiv.org/abs/2206.14648" target=&ldquo;blank&rdquo;>arXiv</a>]  
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2107.11533" target=&ldquo;blank&rdquo;>Contextual Bandits with Reduced Explorations via Logged Data</a><br />
</p>
<ul>
<li><p>Hung Tran-The, <b>Thanh Nguyen-Tang</b>, Sunil Gupta, Santu Rana, Svetha Venkatesh <br /> 
</p>
</li>
<li><p>Under review, 2022 <br />
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="https://openreview.net/pdf?id=sPIFuucA3F" target=&ldquo;blank&rdquo;>Offline Neural Contextual Bandits:  Pessimism, Optimization and Generalization</a><br />
</p>
<ul>
<li><p><b>Thanh Nguyen-Tang</b>, Sunil Gupta, A.Tuan Nguyen, and Svetha Venkatesh <br />  
</p>
</li>
<li><p>ICLR, 2022 <br /> 
</p>
</li>
<li><p><a href="https://offline-rl-neurips.github.io/2021/pdf/28.pdf" target=&ldquo;blank&rdquo;>Workshop on Offline Reinforcement Learning</a>, NeurIPS, 2021 <br /> 
</p>
</li>
<li><p>[<a href="https://arxiv.org/abs/2111.13807" target=&ldquo;blank&rdquo;>arXiv</a>] 
[<a href="assets/poster_NeurIPSW21.pdf" target=&ldquo;blank&rdquo;>Poster</a>]  
[<a href="assets/neuralcb_slides.pdf" target=&ldquo;blank&rdquo;>Slides</a>] 
[<a href="https://github.com/thanhnguyentang/offline_neural_bandits" target=&ldquo;blank&rdquo;>Code</a>]
</p>
</li>
</ul>

</li>
</ul>
<h3><b></b>2021<b></b> </h3>
<ul>
<li><p><a href="https://lyang36.github.io/icml2021_rltheory/camera_ready/5.pdf" target=&ldquo;blank&rdquo;>Sample Complexity of Offline Reinforcement Learning with Deep ReLU Networks</a> <br />
</p>
<ul>
<li><p><b>Thanh Nguyen-Tang</b>, Sunil Gupta, Hung Tran-The, Svetha Venkatesh <br />
</p>
</li>
<li><p>Workshop on Reinforcement Learning Theory, ICML, 2021 <br />
</p>
</li>
<li><p>[<a href="https://arxiv.org/abs/2103.06671" target=&ldquo;blank&rdquo;>arXiv</a>]
[<a href="https://thanhnguyentang.github.io/assets/offrelu.pdf" target=&ldquo;blank&rdquo;>Slides</a>] 
[<a href="https://www.youtube.com/watch?v=xLM5pondWY4" target=&ldquo;blank&rdquo;>Talk</a>]
</p>
</li></ul>
</li>
<li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/17104" target=&ldquo;blank&rdquo;>Distributional Reinforcement Learning via Moment Matching</a><br /> 
</p>
<ul>
<li><p><b>Thanh Nguyen-Tang</b>, Sunil Gupta, Svetha Venkatesh <br /> 
</p>
</li>
<li><p>AAAI, 2021 <br />
</p>
</li>
<li><p>[<a href="http://arxiv.org/abs/2007.12354" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://github.com/thanhnguyentang/mmdrl" target=&ldquo;blank&rdquo;>Code</a>]
[<a href="https://cutt.ly/fkkiAGm" target=&ldquo;blank&rdquo;>Slides</a>] 
[<a href="https://cutt.ly/4kkiJZt" target=&ldquo;blank&rdquo;>Poster</a>] [<a href="https://youtu.be/1fMqZZjy84E" target=&ldquo;blank&rdquo;>Talk</a>] 
</p>
</li>
</ul>

</li>
</ul>
<h3><b></b>2020<b></b></h3>
<ul>
<li><p><a href="http://proceedings.mlr.press/v108/nguyen20a.html" target=&ldquo;blank&rdquo;>Distributionally Robust Bayesian Quadrature Optimization</a><br /> 
</p>
<ul>
<li><p><b>Thanh Tang Nguyen</b>, Sunil Gupta, Huong Ha, Santu Rana, Svetha Venkatesh<br /> 
</p>
</li>
<li><p>AISTATS, 2020 <br /> 
</p>
</li>
<li><p>[<a href="https://arxiv.org/abs/2001.06814" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://github.com/thanhnguyentang/drbqo" target=&ldquo;blank&rdquo;>Code</a>]
[<a href="https://thanhnguyentang.github.io/assets/aistats20_drbqo.pdf" target=&ldquo;blank&rdquo;>Slides</a>] 
[<a href="https://slideslive.com/38930124/" target=&ldquo;blank&rdquo;>Talk</a>]  
</p>
</li>
</ul>

</li>
</ul>
<h3><b></b>2019<b></b> </h3>
<ul>
<li><p><a href="https://doi.org/10.3390/e21100976" target=&ldquo;blank&rdquo;>Markov Information Bottleneck to Improve Information Flow in Stochastic Neural Networks</a><br />
</p>
<ul>
<li><p><b>Thanh Tang Nguyen</b>, Jaesik Choi<br />
</p>
</li>
<li><p>Entropy, 21(10), 976, 2019 <br /> 
</p>
</li>
<li><p>[<a href="https://github.com/thanhnguyentang/pib" target=&ldquo;blank&rdquo;>Code</a>]
</p>
</li></ul>
</li>
<li><p><a href="https://papers.nips.cc/paper/9350-bayesian-optimization-with-unknown-search-space" target=&ldquo;blank&rdquo;>Bayesian Optimization with Unknown Search Space</a><br />
</p>
<ul>
<li><p>Huong Ha, Santu Rana, Sunil Gupta, <b>Thanh Tang Nguyen</b>, Hung Tran-The, Svetha Venkatesh <br />
</p>
</li>
<li><p>NeurIPS, 2019 <br />
</p>
</li>
<li><p>[<a href="https://github.com/HuongHa12/BO_unknown_searchspace" target=&ldquo;blank&rdquo;>Code</a>]
[<a href="https://postersession.ai/poster/bayesian-optimization-with-unknown-searc/" target=&ldquo;blank&rdquo;>Poster</a>]
</p>
</li>
</ul>

</li>
</ul>
<h3>Dissertations </h3>
<ul>
<li><p><a href="https://thanhnguyentang.github.io/" target=&ldquo;blank&rdquo;>On Practical Reinforcement Learning: Provable Robustness, Scalability and Statistical Efficiency</a><br /> 
</p>
<ul>
<li><p>Ph.D. dissertation, Deakin University, Australia, July 2021
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p><a href="http://scholarworks.unist.ac.kr/handle/201301/23561" target=&ldquo;blank&rdquo;>Parametric Information Bottleneck to Optimize Stochastic Neural Networks</a><br />
</p>
<ul>
<li><p>Master Thesis, Ulsan National University of Science and Technology, South Korea, 2018<br />
</p>
</li>
<li><p>[<a href="https://thanhnguyentang.github.io/assets/PIB_thesis_slide.pdf" target=&ldquo;blank&rdquo;>Slides</a>] [<a href="https://www.youtube.com/watch?v=md9qV4Hrgbo&amp;t=378s" target=&ldquo;blank&rdquo;>Talk</a>]
</p>
</li>
</ul>

</li>
</ul>
<h2>Academic Service  </h2>
<ul>
<li><p>Senior Program Committee: AAAI (2023)
</p>
</li>
<li><p>Reviewer/Program Committee: NeurIPS (2022, 2021, 2020), ICML (2022, 2021), ICLR (2023, 2022, 2021- Outstanding reviewer award), AISTATS (2021), 
AAAI (2022, 2021-<a href="https://aaai.org/Conferences/AAAI-21/wp-content/uploads/2021/05/AAAI-21-Program-Committee.pdf" target=&ldquo;blank&rdquo;>Top 25% of Program Committees</a>, 2020), 
EWRL (2022), L4DC (2022), NeurIPS Workshop on Offline Reinforcement Learning (2022, 2021)
</p>
</li>
<li><p>Volunteer: ICML (2022), AutoML (2022)
</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2022-10-25 16:54:10 EDT, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
(<a href="index.jemdoc">source</a>)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
