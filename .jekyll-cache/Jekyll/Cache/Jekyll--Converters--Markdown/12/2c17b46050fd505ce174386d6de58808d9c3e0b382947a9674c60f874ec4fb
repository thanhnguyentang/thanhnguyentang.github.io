I"i<p><a href="/">[Back Home]</a></p>

<p>Maximum entropy sampler: Random notes on random topics (the topic mode is at approximate inference for generalization and robustness in RL and neural networks) for random thoughts.</p>

<!-- A collection of my notes drafted for various topics that I have investigated. I try the best to be self-contained when possible. A new blog post every week with probability of $1/3$. Most posts are in RL, Variational Inference and Information Theory with the goal in mind that they must be both *empirically* and *theoretically* insightful. Some are perspectives and insights about research per se.  -->

<!-- * 16/02/20: [A distributional perspective on learning.](/blogs/distributional) -->

<ul>
  <li>15/04/21: <a href="/blogs/bucket">Todo.</a></li>
  <li>27/02/21: <a href="/blogs/slt.pdf">A Minimal Note on Statistical Foundations of Modern Machine Learning.</a></li>
  <li>07/08/20: <a href="/blogs/convergences_of_rvs">Convergences of random variables.</a></li>
  <li>11/07/20: <a href="/blogs/mlss20.pdf">MLSS 2020 Note.</a></li>
  <li>12/04/20: <a href="/blogs/distributional_analysis">A Note on  Amortila et al. “A Distributional Analysis of Sampling-based RL Algorithms”.</a></li>
  <li>02/02/20: <a href="/blogs/read_map">Roadmap.</a></li>
  <li>21/01/20: <a href="/blogs/paradigm_shift">Paradigm shift.</a></li>
  <li>18/01/20: <a href="/blogs/quotes">My favourite quotes.</a></li>
  <li>30/10/19: <a href="/blogs/q_learning_provable">Q-learning is provably efficient.</a></li>
  <li>20/09/19: <a href="/blogs/rand_great">On patterned ways of thinking.</a></li>
  <li>18/08/19: <a href="/blogs/paper_structures">On some structures in the evolution of research idea in ML.</a> (<em>LAST UPDATED: 27/05/20</em>)</li>
  <li>08/08/19: <a href="/blogs/mdp">MDP basics.</a>
<!-- * 06/08/19: [Concentration Inequalities.](/blogs/concentration_ineq) --></li>
  <li>05/08/19: <a href="/blogs/ac_variants">Actor-Critic Variants and Recursion-Preserving Principle for Incremental Learning.</a></li>
  <li>03/08/19: <a href="/blogs/wisdom">Wisdom in MLAI.</a> (<em>LAST UPDATED: 15/04/20</em>)</li>
  <li>28/07/19: <a href="/blogs/hype_circle">Garner hype circle of your Ph.D.</a></li>
  <li>22/07/19: <a href="/blogs/lagrangian">Lagrangian.</a></li>
  <li>22/07/19: <a href="/blogs/actor_critic">Actor-Critic: Using relative returns to properly scale policy gradients.</a></li>
  <li>19/07/19: <a href="/blogs/sgrl.pdf">From stochastic games to robustness in reinforcement learning.</a> (<em>presented at A2I2@Deakin</em>)</li>
  <li>19/06/19: <a href="/blogs/ot_intro">A naive introduction to Optimal Transport.</a> 
<!-- * 13/05/19: [Who to follow?](/blogs/who_to_follow)  --></li>
  <li>18/04/19: <a href="/blogs/how_to_write_papers">How to write a first-class paper?</a></li>
  <li>21/03/19: <a href="/blogs/functional_prob_space">A basic result of kernel embedding on probability space</a></li>
  <li>20/03/19: <a href="/blogs/rkhs.pdf">Basics of Reproducing Kernel Hilbert Space (RKHS).</a> 
<!-- * 08/08/18: [How Information theory possibly helps AI?](http://mlsidenotes.blogspot.com/2018/08/from-information-theory-to-machine.html) --></li>
  <li>17/06/18: <a href="/blogs/gumbel_softmax">Gumbel-Softmax to Approximate Samples for a Categorical Distribution.</a></li>
  <li>03/06/18: <a href="/blogs/gp_fr.pdf">Fundamental Elements of Gaussian Process.</a></li>
  <li>31/05/18: <a href="/blogs/l2x.pdf">Learning to Explain a Model via Variational Mutual Information, Jianbo Chen et al.</a> (<em>presented at SAIL@UNIST</em>)</li>
  <li>22/05/18: <a href="/blogs/rl_intro.pdf">A Lazy Introduction to Reinforcement Learning: A Supervised Learning Perspective.</a></li>
</ul>

<!-- ## Topics I plan to write on  
* <strike>Actor-critic algorithms in RL: done</strike> 
* Stabilizing and variance-reduction in Actor-Critic:
    * [Catastrophic forgetting and continual learning](https://arxiv.org/abs/1807.04015) 
    * [TD-regularized Actor-Critic methods](https://arxiv.org/abs/1812.08288) 
* Variational Inference in RL:
    * [Deep Variational RL for POMDPs](https://arxiv.org/abs/1806.02426)

* Invariant risk minimization  
* No free lunch theorem   -->
:ET