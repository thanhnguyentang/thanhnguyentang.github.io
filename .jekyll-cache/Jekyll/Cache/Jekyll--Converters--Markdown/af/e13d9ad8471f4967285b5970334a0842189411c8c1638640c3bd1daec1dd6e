I" <p><a href="/">[Back Home]</a>  <a href="/blogs/post">[Back to Blog]</a></p>

<h1 id="research-roadmap">Research Roadmap</h1>

<p>A proposed road to greatness</p>

<ul>
  <li>To become a <strike>good</strike> great scientist, you must first become a healthy, humble and happy human being.</li>
  <li>Start with important questions that you believe many of our community (including both scientific and general community) would appreciate and benefit from if you can give some answer to the questions (if possible, try to avoid something too niche at this stage).</li>
  <li>Maintain good friendships and collaborations because important problems for our community need collaborative efforts to address. In addition, diverse perspectives from collaborations help you learn faster and more robust.</li>
  <li>Original thinker and perseverant doer.</li>
  <li>Put your whole heart on whatever you do; your readers will know it.</li>
</ul>

<!-- Roadmap for Theory of DL (Goal: a unifying theory for representation and generalization in DL that connects many related disciplines and ideas. This unifying theory, if exists, shoud require a graceful interplay among Information Theory, Probability Theory, Optimal Transport and Optimization): 
* Some (important) AI paradigms to play with: RL, GAN, neural density estimation.  
* Understand RL via OT;  
* Understand GAN dynamics via OT or Information Theory;  
* Understand generalization in DNNs via Information Theory perspective or OT (e.g., [Stronger generalization bounds for deep nets via a compression approach](https://arxiv.org/pdf/1802.05296.pdf));   
* A Unifying framework for OT, IT, DL, Statistics and Optimization (hint: Variational inference is an optimization-based inference)
* Use these new insights to improve practical algorithms and find impactful, empirical applications.  -->

<h1 id="scientist-roadmap">Scientist Roadmap</h1>

<p>There are many researchers I wish to learn from their work and research styles for my research career. Basicially, in my perspective, they, novelly and insightfully address important problems in Machine Learning and Artifical Intelligence from first principles approach by borrowing perspectives from probability theory, statistics, information theory, optimal transport and optimization.  As a result, their research gives novel perspectives,  and has sufficient impact on our community (based on 4 metrics: (i) potential applications, (ii) number of citations, (iii) generalization of technical knowledge, and (iv) giving new understanding of MLAI problems).</p>

<!-- bring many new perspectives  -->

<!-- in a novel but insightful manner, bring Probability Theory, Statistics, Optimal Transport, Information Theory, and Optimization into Machine Learning and Artificial Intelligence. Their research gives novel perspectives, has sufficient impact on our community (based on 4 metrics: (i) potential applications, (ii) number of citations, (iii) generalization of technical knowledge, and (iv) giving new understanding of MLAI problems).  -->

<p>To learn from this route is one of my goals; but this task is apparently not easy, given that I have many such researchers that I wish to learn from at some point of my career. In addition, to distill what common pattern thinkings I need to learn from and how should I apply these extracted principles to my own situation is not trivial. To make this task more manageable and doable, I try to make a project-based roadmap; that is, a small (varying) list of researchers I wish to learn more from based on my <b>current</b> projects (so once a project is done, the list might change):</p>

<!-- This generic style is exactly the one I am pursuing. But to make this task more manageable and doable, I try to make a project-based roadmap; that is, a small (varying) list based on my <b>current</b> projects (so once a project is done, the list might change): -->

<ul>
  <li><a href="https://scholar.google.com/citations?user=A6qfFPkAAAAJ&amp;hl=en">Martin Arjovsky</a></li>
  <li><a href="https://sites.google.com/view/markrowland">Mark Rowland</a></li>
</ul>

<!-- * [Ian Murray](https://homepages.inf.ed.ac.uk/imurray2/)  
* [Martin Wainwright](https://scholar.google.com/citations?user=J5Rvh6gAAAAJ&hl=en)  
* [Gabor Lugosi](https://scholar.google.com/citations?user=WgPhMfwAAAAJ&hl=en)   -->

<h1 id="good-environment-vibes">Good environment vibes</h1>

<p>A batch of random samples of good environment vibes to do world-class research. 
<!-- I can feel the vibes. --></p>
<ul>
  <li><a href="https://ei.is.tuebingen.mpg.de/publications">Empirical Inference at Max Planc Institute for Intelligence Systems</a></li>
  <li><a href="http://mlg.eng.cam.ac.uk/pub/">Machine Learning Group at Cambridge</a></li>
  <li><a href="https://deepmind.com/">Deepmind</a></li>
  <li><a href="http://tensorlab.cms.caltech.edu/users/anima/publications.html">Tensorlab at Caltech</a></li>
  <li><a href="https://research.cs.aalto.fi/pml/publications.shtml">Probabilistic Machine Learning Group at Aalto</a></li>
  <li><a href="https://aip.riken.jp/labs/generic_tech/approx_bayes_infer/?lang=en">Approximate Bayesian Inference Group at RIKEN</a></li>
</ul>

<h1 id="research-advice-roadmap">Research advice roadmap</h1>
<ul>
  <li><a href="https://moscow.sci-hub.tw/1254/a812ddf37f1ed6d0df5467996e1a4cf4/dyson1983.pdf">Unfashionable Pursuits</a> by Freeman J. Dyson.</li>
  <li><a href="https://www.uky.edu/~eushe2/Pajares/kuhnsyn.html">The Structure of Scientific Revolutions</a> by Thomas S. Kuhn: After some time of being exploited, research paradigm shifts when anomaly is encountered (read more summary <a href="https://thanhnguyentang.github.io/blogs/paradigm_shift">here</a>).</li>
  <li><a href="http://www.cs.virginia.edu/~robins/YouAndYourResearch.html">You and Your Research</a> by Richard Hamming (read more summary <a href="https://thanhnguyentang.github.io/blogs/wisdom">here</a>).</li>
  <li><a href="http://michaelnielsen.org/blog/principles-of-effective-research/">Principles of Effective Research</a> by Michael Nielsen: the foundation of effective research is a strong motivation or desire to do research, but you should not trade your research with your family and happiness.</li>
  <li><a href="http://joschu.net/blog/opinionated-guide-ml-research.html">An Opinionated Guide to ML Research</a> by John Schulman: Work on the right problems, make continual progress on them, and achieve continual personal growth.</li>
</ul>

<h1 id="good-books">Good books</h1>

<p>Some great books that I have been reading.</p>

<ul>
  <li>Shun-ichi Amari. <a href="https://www.springer.com/gp/book/9784431559771">Information Geometry and its Applications</a>. (ongoing)</li>
  <li>Villani CÃ©dric. <a href="https://www.springer.com/gp/book/9783540710493">Optimal Transport: Old and New</a>. (ongoing)</li>
  <li>Thomas M. Cover and Joy A. Thomas. <a href="http://staff.ustc.edu.cn/~cgong821/Wiley.Interscience.Elements.of.Information.Theory.Jul.2006.eBook-DDU.pdf">Elements of Information Theory</a>. (finished in general)</li>
</ul>
:ET