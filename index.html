
<html>

    <head>
		 <script type="text/x-mathjax-config">
			   MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
		 </script>
		 <script type="text/javascript"
	     src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		 </script>
        <meta charset="UTF-8"> 
        <link rel="stylesheet" href='css/style3.css'>
        
        <SCRIPT TYPE="text/javascript"> 
        function popup(mylink, windowname)
        {
            if (! window.focus)
                return true;
            var href;
            if (typeof(mylink) == 'string')
                href=mylink;
            else
                href=mylink.href;
            window.open(href, windowname, 'width=750,height=300,scrollbars=yes');
                return false;
        }
            //-->
        </SCRIPT> 
        <title>thanhnguyentang</title>
    </head>
    
    <style type="text/css">
    .journal { color: #117711; }
    </style>
    
    <body>
            <div>
            <!--
            <center>
            <img src="images/banner.jpg" width=100%>
            </center>
            -->
            
            <div style='float:right;width:255; padding:5px; margin:15px; margin-right:-5px; border-left:1px solid #000000'>
            
                <center>
                <b>Upcoming Events</b>
                </center>
            
                <div class='event' style='background-color:#EECCAA'>
                    <b><font color="#888888">03-05/06/20</font></b> 
                    <a href="https://www.aistats.org/"><b>AISTATS</b> 2020</a> in Palermo, Sicily, Italy. 
                </div>
                
                
                <center>
                    <b>News</b>
                </center>
                
                <div class='event'> 
                    <b><font color="#888888">07/01/20</font></b>
                    Our paper, "<b><i>Distributionally robust Bayesian quadrature optimization</i></b>" 
                    has been accepted to  <a href="https://www.aistats.org/"><b>AISTATS</b> 2020</a> (Palermo, Italy). <br> <br>

                    <b><font color="#888888">30/09/19</font></b> 
                    Our manuscript on "<b><i>Markov information bottleneck</i></b>" has been accepted to 
                    <a href="https://www.mdpi.com/journal/entropy">Entropy journal</a>. 
                    Special thanks to Dr. <a href="https://scholar.google.com/citations?user=LzQ2jAwAAAAJ&hl=en">Bernhard C. Geiger</a>
                    for inviting us to contribute to Entropy. <br> <br>

                    <b><font color="#888888">04/09/19</font></b> 
                    Our paper on "<b><i>Bayesian optimization with unknown search space</i></b>" has been accepted to 
                    
                    <a href="https://neurips.cc/Conferences/2019/AcceptedPapersInitial"><b>NeurIPS</b> 19'</a>, congrats Dr.
                    <a href="https://scholar.google.com.au/citations?user=Uf3o7_UAAAAJ&hl=en">Huong Ha</a>! <br> <br> 
                    <b><font color="#888888">16/01/19</font></b> I started Ph.D. in Jan. 2019 in <a href="https://a2i2.deakin.edu.au/">A2I2@Deakin</a> (Australia). <br> <br>
                    
                    <b><font color="#888888">20/11/17</font></b> I defended my Master with A/Prof. J. Choi, A/Prof. <a href="http://bmipl.unist.ac.kr/">S. Y. Chun</a> and 
                    Assistant Prof. <a href="https://junmoony.github.io/">J. Moon</a> (now at University of Seoul) at UNIST. 
                </div>
            
            </div>
                    <!--
                    
                    <div style="width:10%;float:left">
                    <img alt="Thanh T. NGUYEN, T.T. Nguyen, Thanh Nguyen" src="Profile.jpg" style="display:inline;margin:5px 10px 0px 0px;float:left" width="150">
                    <a href="/personal/images" target="_blank"><font size="1">more images</font></a>
                    </div>

                -->
                <br> 
                <br>
                <img alt="Thanh T. NGUYEN, T.T. Nguyen, Thanh Nguyen" src="images/IMG_4751.jpeg" 
                style="display:inline;margin:5px 10px 0px 0px;float:left" width="120">
                <b>Thanh Tang NGUYEN</b>  <br>
                <a href="https://a2i2.deakin.edu.au/" target="_blank">Applied AI Institute (A2I2)</a><br> 
                <a href="http://www.deakin.edu.au/" target="_blank">Deakin University</a><br> 
                75 Pigdons Rd, Highton VIC 3216, Australia<br> 
                Email: thanhnt [AT] deakin.edu.au / nguyent2792 [AT] gmail.com <br>
                <!--<img src="images/Email.png" alt="Email" height="42"><br>-->
                <br>
                [ <a href="/assets/thanhnt_resume.pdf" target="_blank">CV</a> | 
                    <a href="https://github.com/thanhnguyentang" target="_blank">Github</a> | 
                    <a href="/blogs/post">Notes</a> | 
                    <a href="https://scholar.google.com/citations?hl=en&user=UrTlMiwAAAAJ" target="_blank">Google Scholar</a> | 
                    <a href="https://www.researchgate.net/profile/Thanh_Nguyen298" target="_blank">ResearchGate</a> |  
                    <a href="https://twitter.com/thanhnguyentang" target="_blank">Twitter</a> ]
                    

            <p>
            I am currently a PhD candidate at the Applied AI Institute of Deakin University 
            under the supervision of A/Prof. <a href="https://scholar.google.com.au/citations?user=bXeL2t8AAAAJ&hl=en">Sunil Gupta</a>, 
                                A/Prof. <a href="https://scholar.google.com.au/citations?user=S9PwnMYAAAAJ&hl=en">Santu Rana</a>, 
                                A/Prof. <a href="https://scholar.google.com.au/citations?user=zvspVLwAAAAJ&hl=en">Truyen Tran</a>, and 
                                Alfred Deakin Prof. <a href="https://scholar.google.com.au/citations?user=AEkRUQcAAAAJ&hl=en">Svetha Venkatesh</a>. 
            Prior to that, I was working as a researcher under A/Prof. <a href="http://sail.unist.ac.kr/members/jaesik/">Jaesik Choi</a> 
            (now at <a href="https://sites.google.com/a/kaist.edu/song-chong/kaist-graduate-school-of-ai">KAIST</a>) at <a href="http://sail.unist.ac.kr/" target="_blank">SAIL@UNIST</a> 
            where I also obtained a master degree in 2018. Before that, I obtained my B.Eng. in the Center of Excellence, Danang University of Science and Technology in 2015.  
            <!-- <br>
            My ha-index is 70.  -->
            <br><br>
            <!-- My research interest is in the ideas that involve distribution discrepancy and their application specifically in reinforcement learning.  
            I am also strongly motivated by empirical AI problems of designing a lifelong, continual-learning, and self-improving agent that becomes more general and smarter under minimal supervision 
            (sufficiently general AI).  -->

            
            <!-- One day, such a agent can become general enough that it can help us free our labor in many repeated tasks and gives us more freedom to do more great things. 
            I am still skeptical of a truly general AI, but I believe that we can make it a lots more general than it is today, and 
            <i>sufficiently general </i> AI is the future of AI that I believe.  -->

            <!-- My underlying mission is to make Machine Learning and Artificial Intelligence (MLAI) more fun, more accessible, and more powerful.
            My broad interests are in the ideas that involve playing with distributions in an online manner and are strongly inspired by important emprical problems.   -->
            <!-- My broad interests are in the ideas that involve sequential decision making under uncertainty, probability, information theory and neural networks  -->
            <!-- with empirical motivations.  -->

            <!-- My research goal is to develop more theoretically principled algorithms with deeper understanding and stronger empirical performance for important AI problems. 
            My research interests lie in the algorithmic, foundational and empirical dimensions at the intersection of machine learning, optimization, statistics and information theory; particularly: -->
            <!-- Currently, I mainly focus on optimization and exploration perspective in reinforcement learning, and a bit on uncertainty and generalization in deep neural networks.   -->
            My goal is to understand machine intelligence from a computational perspective. 
            To this end, I study inference, optimization and statistics. My current research interests (settings) are: 
            <ul>
                <li>Reinforcement learning;</li> 
                <li>Optimal transport;</li>
                <li>Optimization;</li>
                <li>Information bottleneck;</li>
                <li>Probabilistic modelling and inference; </li> 
                <li>GANs.</li>
                <!-- <li>Information Theory; </li>   -->
                <!-- <li>Uncertainty and generalization in deep (stochastic) neural networks. </li> -->
                <!-- <li>Applications: Neural Reading Comprehension and Medical Imaging.</li> -->

            </ul>


            <!-- <br><br> -->
            
            <!-- <b>Keywords</b>: Reinforcement Learning; Distributional Learning; Variational Bayes; Uncertainty; Information Theory; Generalization in DNNs.  -->
            
            <!-- I identify my works to ICML, NeurIPS, AISTATS, AAAI, ICLR and Transactions on Information Theory.  -->



            <!-- I am interested in leveraging and developing principled approaches rooted in optimization, statistics and information theory to attack empirical AI problems. My current research interests: -->
		<!-- <ul>
            <li>Reinforcement Learning</li> 
            <li>Optimal Transport</li> 
            <li>Bayesian Statistics</li>
			<li>Variational Inference</li> posterior collapse problem
            <li>Information Theory</li> information bottleneck

        </ul>  -->
            <!--
            My long-term research effort is to seek for general computational principles underlying so-called <i>intelligence</i>. I believe that at the core of intelligence is the ability to <i>learn</i> under various <i>learning paradigms</i>. By learning, I mean the ability to generalize from past experience without exhaustedly experiencing all the intractable search space. By learning paradigms, I refer to <i>incremental</i> learning, i.e., to learn incrementally on a sample or episode or sequential basis (which is beneficial for scalability), either from interactions (as in reinforcement learning), or from external supervision (as in supervised learning), or for reconstruction (as in unsupervised learning). Currently, I am focusing on reinforcement learning, information-theoretic deep learning, and Bayesian statistics with vast applications in NLP, computer vision and healthcare. In particular, I am specially interested in the trade-off aspect of <i>learning</i> such as exploration-exploitation trade-offs in reinforcement learning, compression-relevance trade-offs in information bottleneck, and explainability-performance in explainable artificial intelligence. <br> <br>

            I avocate the "think-globally-act-locally" philosophy, promoting doing research in important Machine Learning and Artificial Intelligence problems by the means of <i>incrementality</i>, <i>simplicity</i> and <i>transparency</i>. 

            </p>

            <h2> Education</h2>
            <ul>
                <li> 2016/03-2018/02: M.Sc. in Computer Science and Engineering <br> <a href="http://unist.ac.kr/" target="_blank">
                Ulsan National Institute of Science and Technology (UNIST)</a>, Korea (GPA: 4.3 / 4.0)<br>
                </li>
                <li> 2010/09-2015/07: B.Sc. in Electronic and Communication Engineering <br> <a href="http://dut.udn.vn/EN" 
                target="_blank">Danang University of Science and Technology</a>, Vietnam (Valedictorian)<br>
                </li>
            </ul>

            <h2>Experience</h2>

            </li>

            <li>2016/03-2018/03: Research Assistant and Teaching Assistant at <a href="http://sail.unist.ac.kr/" target="_blank">Statistical Artificial Intelligence Lab</a>, UNIST

            </li>
            </ul>

            -->
            <h2>Publications</h2>
                <ul>
                <li><b>TT Nguyen</b>, S. Gupta, H. Ha, S. Rana, and S.Venkatesh <br>
                    <i>Distributionally robust Bayesian quadrature optimization</i>. [<a href="https://arxiv.org/abs/2001.06814">arXiv</a>]<br> 
                            
                    <span class="journal"> Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (<b>AISTATS</b>), Palermo, Italy, <b>2020</b>.
                    
                    </span>
                
                </li>

                    <li><b>TT Nguyen</b>, and J. Choi<br>
                    <i>Markov information bottleneck to improve information flow in stochastic neural networks</i>.
                [ <a href ="https://doi.org/10.3390/e21100976">DOI</a> | <a href="https://github.com/thanhnguyentang/pib">code</a> | <a href="bibtex/nguyen-pib17.txt" onclick="return popup(this, 'bibtex')">bibtex</a> ]<br> 
                    <span class="journal"><b>Entropy</b>, 21(10), 976, <b>2019</b> (in <a href="https://www.mdpi.com/journal/entropy/special_issues/information_theoretic_computational_intelligence">
                        <b>Information Bottleneck: Theory and Applications in Deep Learning</b></a>).</span> </li>

                    <li>H. Ha, S. Rana, S. Gupta, <b>TT Nguyen</b>, H. Tran-The, and S. Venkatesh
                        <br>
                        <i>Bayesian optimization with unknown search space</i>. [ <a href="https://papers.nips.cc/paper/9350-bayesian-optimization-with-unknown-search-space">link</a> | <a href="https://postersession.ai/poster/bayesian-optimization-with-unknown-searc/">poster</a> | <a href="https://github.com/HuongHa12/BO_unknown_searchspace">code</a> | <a href="bibtex/huong_neurips19.txt" onclick="return popup(this, 'bibtex')">bibtex</a> ]<br>
                        <span class="journal">Proceedings of the Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 32, Vancouver, BC, Canada, 8â€“14 December, <b>2019</b>.</span>
                        </li>
                    <li><b>TT Nguyen</b> <br>
                        <i>Parametric information bottleneck to optimize stochastic neural networks</i>. [ <a href="http://scholarworks.unist.ac.kr/handle/201301/23561">link</a> | <a href="/assets/pib_slide_v4.pdf">slide</a> | <a href="https://www.youtube.com/watch?v=md9qV4Hrgbo&t=378s">talk</a> | <a href="bibtex/nguyen-master18.txt" onclick="return popup(this, 'bibtex')">bibtex</a> ]
                        <br><span class="journal">Graduate School of UNIST, <b>Master Thesis</b>, <b>2018</b>.</span> </li>
                    <li><b>TT Nguyen</b>, and J. Choi <br>
                        <i>Parametric information bottleneck to optimize stochastic neural networks</i>. (<b>Best Poster Award</b>) [ <a href="http://www.kiise.or.kr/data/pdf/PACS2017_Proceedings.pdf">link</a> ] <br>
                        <span class="journal"> Proceedings of the International Symposium on Perception, Action and Cognitive Systems (<b>PACS</b>), p. 23-30, Seoul, Korea, <b>2017</b>. </span>
                        <!-- [<a href="http://www.kiise.or.kr/conference/PACS/2017/" target="_blank">Best Poster Award</a>] -->
                    </li>
                <!--<li>TT Nguyen, D Nguyen, and SJ Hwang. <a href="https://arxiv.org/abs/1811.08594">Learning to Attend Relevant Regions in Videos from Fixations</a><br> <span class="journal">Technical Report, arXiv:1811.08594, 2016</span></li>
            -->
                </ul>
            <!-- <h4>Preprints</h4> -->
            <!-- <ul> -->
                <!-- <li><b>TT Nguyen</b>, S. Gupta, H. Ha, S. Rana, and S.Venkatesh. Distributionally Robust Bayesian Quadrature Optimization. 
                    <b>Submitted</b>. <br> 
                    <span class="journal">Under review, <b>2019</b>.</span></li> -->
            <!-- </ul> -->

            <h2>Others</h2>
                <b>Service</b> 
                <ul>
                    <li> 
                        Invited reviewer: <b>IJCNN 2020</b>; support reviewer: <b>AISTATS 2018</b>, <b>ICLR 2020</b>. 
                    </li>

                </ul>
                <b>Teaching</b> 
                <ul>
                    <li>
                        <a href="http://sail.unist.ac.kr/">UNIST</a>: Advanced Machine Learning (TA, <b>2017</b>);  Engineer Programming (TA, <b>2016</b>).
                    </li>
                    <li>
                        <a href="http://fast.dut.udn.vn/en/">CoE@DUT</a>: Machine Learning (TA, <b>2015</b>); Digital Signal Processing (TA, <b>2014</b>); Advanced Calculus and Algebra (TA, <b>2011-2015</b>). 
                    </li>
                </ul>
            
                <b> Past projects </b>
                <ul>
                    <!-- <li><a href="https://www.researchgate.net/project/Neural-Reading-Comprehension">Neural Reading Comprehension in SQuAD 2.0</a><br><span class="journal">2018-</span></li>
                    <li><a href="https://www.researchgate.net/project/Information-Theoretic-Interpretation-of-Deep-Neural-Networks">Information-Theoretic Interpretation of Deep Neural Networks</a><br><span class="journal">2017-</span></li> -->
                    <li>Neural reading comprehension (collaborators: <a href="https://scholar.google.co.kr/citations?user=N9ZM-CIAAAAJ&hl=ko">S. Kwon</a>, J.C.)
                        <br>
                        <span class="journal">NLP project for SQuAD dataset, <b>2018</b>.</span> </li>
                    </li>

                    <li>Deep Learning based Real-Time Pedestrian Detection for CCTV 
                        (collaborators: <a href="https://scholar.google.com/citations?user=ZKhDYmUAAAAJ&hl=en">R. Lima</a>, and J.C.). [ <a href="http://saildemo.unist.ac.kr/pedestrian_detection/">demo</a> ]  <br>
                        <span class="journal">NIPA project, <b>2016</b>.</span> </li>

                    <li>Lesion Dermoscopic Feature Segmentation (ranked <b>1st</b>) and Lesion Segmentation (ranked <b>8th</b>) 
                        (collaborators: <a href="https://github.com/LieCOS">J. Ju</a>, 
                        <a href="https://haebeom-lee.github.io/">H. Lee</a>, 
                        <a href="http://bmipl.unist.ac.kr/">S.Y. Chun</a>, and J.C.). [ <a href="https://github.com/thanhnguyentang/melanoma_tutorial">code</a> | 
                         <a href="https://seyoungchun.wordpress.com/2016/04/15/posters-and-challenge-results-at-the-2016-international-symposium-on-biomedical-imaging-isbi/">BMIPL News</a> 
                         | <a href="http://sail.unist.ac.kr/ieee-isbi-2016-challenge-rank-1st-and-3rd-in-skin-cancer-classification-challenges/">SAIL News</a> ]<br>
                        
                        <span class="journal">ISBI 2016: Skin Lesion Analysis Towards Melanoma Detection, <b>2016</b>.</span> 
                    </li>

                </ul>
            
            <!--
                <h2> Activities </h2>
                <ul>
                    <li>
                    2018/10/12: Attended <a href="http://xai.unist.ac.kr/Symposium/2018/" target="_blank">International Explainable AI Symposium 2018</a>, Seoul, Korea.
                    </li>
                    <li>
                    2017/11/15-17: Attended <a href="http://www.acml-conf.org/2017/" target="_blank">the Asian Conference on Machine Learning (ACML) 2017</a>, Seoul, Korea.
                    </li>

                    <li>
                    2017/11/02-03: Attended <a href="http://www.kiise.or.kr/conference/PACS/2017/" target="_blank">the International Symposium on Perception, Action, and Cognitive Systems (PACS)</a>, Seoul, Korea.
                    </li>

                    <li>
                    2016/06/02-03: Attended <a href="http://mlcenter.postech.ac.kr/ml_symposium_2016_program" target="_blank">the First Korea-Japan Machine Learning Symposium</a>, Seoul, Korea.
                    </li>
                </ul>
            -->
            <!--
                <h2>Highlight</h2>
            
                <center>
                    <div style='display:inline-block;vertical-align:top;margin:10px;width:200px;color:#555555'>
                    <a alt="Fix2Att" href="/assets/[AML]relevant-from-fixations.pdf" target="_blank"><img src="assets/Ik3nhT4.gif" width=200px height=150px style="border:solid 2px #AAAAAA"></a><br><b>Attention from Fixations:</b> The model learns to attend to the salient regions in the videos from eye fixations. 
                    </div>
                    <div style='display:inline-block;vertical-align:top;margin:10px;width:200px;color:#555555'>
                    <a alt="PedestrainDetection" href="http://saildemo.unist.ac.kr/pedestrian_detection/" target="_blank"><img src="images/nipa_model.png" width=200px height=150px style="border:solid 2px #AAAAAA"></a><br><b>Pedestrian Detection:</b> The region proposal network directly predicts boxes of various scales at each position in an image. 
                    </div>
                    <div style='display:inline-block;vertical-align:top;margin:10px;width:200px;color:#555555'>
                    <a alt="PIB" href="https://arxiv.org/pdf/1712.01272v4.pdf" target="_blank"><img src="images/pib_model.png" width=200px height=150px style="border:solid 2px #AAAAAA"></a><br><b>PIB:</b> Each layer in DNNs is considered as a bottleneck that splits the architecture into an encoder and a variational relevance decoder. Compression and relevance are then induced at each bottleneck.
                    </div>
                    <div style='display:inline-block;vertical-align:top;margin:10px;width:200px;color:#555555'>
                    <a alt="Squad" href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank"><img src="images/squad20.png" width=200px height=150px style="border:solid 2px #AAAAAA"></a><br><b>Reading Comprehension:</b> The network answers to a question relevant to a context by selecting a span in the context. The question might or might not be answerable. 
                    </div>
                </center>
                -->
                
            
                
            
            
            
            <!--
            <div>
            <a href="https://info.flagcounter.com/btag"><img src="https://s05.flagcounter.com/count/btag/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_1/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a>   
            </div>
            -->

        <i><font size="1">Last updated: 2020. </font></i> <br>
        <i><font size="1"> Built with <a href="https://jekyllrb.com/">Jekyll</a> | Inspired by <a href="http://heatmapping.org/" target="_blank">heatmapping</a>.</font></i><br><br>
        <!-- <i><font size="1">Every new day is blessed; one idea, one experiment, one proof at a time.</font></i> -->
    </div>
            <!--<p><font size="4" color="red">"Stand on the shoulders of giants"</font></p> -->
    </body>
</html>
    
