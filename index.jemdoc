# jemdoc:index.html, showsource 
= Thanh Nguyen-Tang
Postdoctoral Research Fellow \n
[https://www.cs.jhu.edu/ Department of Computer Science] \n 
[https://engineering.jhu.edu/ Whiting School of Engineering] \n 
[https://www.jhu.edu/ Johns Hopkins University] \n \n
Malone Hall 331, 3400 N Charles Street, Baltimore, MD 21218 \n \n 
_Email_ /nguyent/ at cs dot jhu dot edu \/ /thnguyentang/ at gmail dot com \n 
_Links_ [https://scholar.google.com/citations?hl=en&user=UrTlMiwAAAAJ&view_op=list_works&sortby=pubdate Google Scholar], 
[https://www.semanticscholar.org/author/Thanh-Nguyen-Tang/1490490191?sort=pub-date Semantic Scholar], 
[https://github.com/thanhnguyentang Github],
[https://twitter.com/thanhnguyentang Twitter] 

== About Me  
I am a Postdoctoral Research Fellow in Department of Computer Science at Johns Hopkins University, 
working with [https://www.cs.jhu.edu/~raman/Home.html Raman Arora]. I was an Associate Research Fellow at the Applied AI Institute, Deakin University in July 2021-June 2022 
and completed my PhD there in Feb 2022. I did my Master in Computer Science and Engineering at Ulsan National Institute of Science and Technology (UNIST) in 2018. 

== Research Interests 
I am building toward data-efficient, runtime-efficient and robust AI 
by studying three foundational pillars of modern machine learning -- provable statistical efficiency, computational efficiency, and robustness. My current focus includes: 

- Reinforcement Learning 
- Learning under Distributional Shifts 
- Robust Adversarial Learning 
- Probabilistic Deep Learning 
- Representation Learning 

Iâ€™m always actively open to research collaborations and chat!


== Recent News  
- Nov. 19, 2022: One paper accepted to AAAI, 2023 (acceptance rate: 19.6%). 
- Oct. 30, 2022:  I was acknowledged in Francis Bach's [https://www.di.ens.fr/~fbach/ltfp_book.pdf "Learning Theory from First Principles"]
- Sep. 14, 2022: One paper accepted to NeurIPS, 2022. 
- Aug. 8, 2022: I am acknowledged in Mengyan Zhang's PhD thesis. 
- Jan. 21, 2022: One paper accepted to ICLR, 2022. 
- May 20, 2021: Accepted to the Deep Learning Theory Summer School at Princeton (acceptance rate: 180/500 = 36%).

== Publications  
=== 2023  

- On Instance-Dependent Bounds for Offline Reinforcement Learning with Linear Function Approximation\n 
    -- _Thanh Nguyen-Tang_, Ming Yin, Sunil Gupta, Svetha Venkatesh, Raman Arora \n 
    -- AAAI, 2023 \n

=== 2022  
- TIPI: Test Time Adaptation with Transformation Invariance\n 
    -- A. Tuan Nguyen, _Thanh Nguyen-Tang_, Ser-Nam Lim, Philip Torr \n
    -- Under review, 2022 \n

- [https://openreview.net/pdf?id=Yl_4LpR_3Z Improving Domain Generalization with Interpolation Robustness]\n 
    -- Ragja Palakkadavath, _Thanh Nguyen-Tang_, Sunil Gupta, Svetha Venkatesh \n
    -- Distribution Shifts Workshop@NeurIPS2022, INTERPOLATE@NeurIPS2022 (/Spotlight/)\n
    -- Under review, 2022 \n

- Provably Efficient Neural Offline Reinforcement Learning via Perturbed Rewards\n 
    -- _Thanh Nguyen-Tang_, Raman Arora \n 
    -- Under review, 2022 \n


- [https://openreview.net/pdf?id=lTZBRxm2q5 Learning Fractional White Noises in Neural Stochastic Differential Equations]\n  
    -- Anh Tong, _Thanh Nguyen-Tang_, Toan Tran, Jaesik Choi \n
    -- NeurIPS, 2022 \n 
    -- \[[https://github.com/anh-tong/fractional_neural_sde Code]\] 

- Two-Stage Neural Contextual Bandits for Adaptive Personalised Recommendation\n  
    -- Mengyan Zhang, _Thanh Nguyen-Tang_, Fangzhao Wu, Zhenyu He, Xing Xie, Cheng Soon Ong \n
    -- Under review, 2022 \n 
    -- \[[https://arxiv.org/abs/2206.14648 arXiv]\]  

- Contextual Bandits with Reduced Explorations via Logged Data\n
    -- Hung Tran-The, _Thanh Nguyen-Tang_, Sunil Gupta, Santu Rana, Svetha Venkatesh \n 
    -- Under review, 2022 \n
    -- \[[https://arxiv.org/abs/2107.11533 arXiv]\]

- [https://openreview.net/pdf?id=sPIFuucA3F Offline Neural Contextual Bandits:  Pessimism, Optimization and Generalization]\n
    -- _Thanh Nguyen-Tang_ , Sunil Gupta, A.Tuan Nguyen, and Svetha Venkatesh \n  
    -- ICLR, 2022 \n 
    -- [https://offline-rl-neurips.github.io/2021/pdf/28.pdf Workshop on OfflineRL], NeurIPS, 2021 \n 
    -- \[[https://arxiv.org/abs/2111.13807 arXiv]\] 
\[[assets/poster_NeurIPSW21.pdf Poster]\]  
\[[assets/neuralcb_slides.pdf Slides]\] 
\[[https://github.com/thanhnguyentang/offline_neural_bandits Code]\]

=== **2021** 
- [https://lyang36.github.io/icml2021_rltheory/camera_ready/5.pdf Sample Complexity of Offline Reinforcement Learning with Deep ReLU Networks] \n
    -- _Thanh Nguyen-Tang_, Sunil Gupta, Hung Tran-The, Svetha Venkatesh \n
    -- Workshop on Reinforcement Learning Theory, ICML, 2021 \n
    -- \[[https://arxiv.org/abs/2103.06671 arXiv]\]
\[[https://thanhnguyentang.github.io/assets/offrelu.pdf Slides]] 
\[[https://www.youtube.com/watch?v=xLM5pondWY4 Talk]]
- [https://ojs.aaai.org/index.php/AAAI/article/view/17104 Distributional Reinforcement Learning via Moment Matching ]\n 
    -- _Thanh Nguyen-Tang_, Sunil Gupta, Svetha Venkatesh \n 
    -- AAAI, 2021 \n
    -- \[[http://arxiv.org/abs/2007.12354 arXiv]] \[[https://github.com/thanhnguyentang/mmdrl Code]]
\[[https://cutt.ly/fkkiAGm Slides]] 
\[[https://cutt.ly/4kkiJZt Poster]] \[[https://youtu.be/1fMqZZjy84E Talk]] 

=== **2020**
- [http://proceedings.mlr.press/v108/nguyen20a.html Distributionally Robust Bayesian Quadrature Optimization]\n 
    -- _Thanh Nguyen-Tang_, Sunil Gupta, Huong Ha, Santu Rana, Svetha Venkatesh\n 
    -- AISTATS, 2020 \n 
    -- \[[https://arxiv.org/abs/2001.06814 arXiv]] \[[https://github.com/thanhnguyentang/drbqo Code]]
\[[https://thanhnguyentang.github.io/assets/aistats20_drbqo.pdf Slides]] 
\[[https://slideslive.com/38930124/ Talk]]  

=== **2019** 
- [https://doi.org/10.3390/e21100976 Markov Information Bottleneck to Improve Information Flow in Stochastic Neural Networks]\n
    -- _Thanh Nguyen-Tang_, Jaesik Choi\n
    -- Entropy, 21(10), 976, 2019 \n 
    -- \[[https://github.com/thanhnguyentang/pib Code]]
- [https://papers.nips.cc/paper/9350-bayesian-optimization-with-unknown-search-space Bayesian Optimization with Unknown Search Space]\n
    -- Huong Ha, Santu Rana, Sunil Gupta, _Thanh Nguyen-Tang_, Hung Tran-The, Svetha Venkatesh \n
    -- NeurIPS, 2019 \n
    -- \[[https://github.com/HuongHa12/BO_unknown_searchspace Code]]
\[[https://postersession.ai/poster/bayesian-optimization-with-unknown-searc/ Poster]]


=== Dissertations 
- [https://thanhnguyentang.github.io/ On Practical Reinforcement Learning: Provable Robustness, Scalability and Statistical Efficiency]\n 
    -- Ph.D. dissertation, Deakin University, Australia, July 2021

- [http://scholarworks.unist.ac.kr/handle/201301/23561 Parametric Information Bottleneck to Optimize Stochastic Neural Networks]\n
    -- Master Thesis, Ulsan National University of Science and Technology, South Korea, 2018\n
    -- \[[https://thanhnguyentang.github.io/assets/PIB_thesis_slide.pdf Slides]] \[[https://www.youtube.com/watch?v=md9qV4Hrgbo&t=378s Talk]]


== Academic Service  
- Senior Program Committee: AAAI (2023)
- Reviewer/Program Committee: NeurIPS (2022, 2021, 2020), ICML (2022, 2021), ICLR (2023, 2022, 2021- Outstanding reviewer award), AISTATS (2021), 
AAAI (2022, 2021-[https://aaai.org/Conferences/AAAI-21/wp-content/uploads/2021/05/AAAI-21-Program-Committee.pdf Top 25% of Program Committees], 2020), 
EWRL (2022), L4DC (2022), NeurIPS Workshop on OfflineRL (2022, 2021)
- Volunteer: ICML (2022), AutoML (2022) 

== Invited Talks 

- Provable Offline Reinforcement Learning: Neural Function Approximation, Randomization, and Sample Complexity 
    -- VinAI, Vietnam, Jan. 13, 2023 

- Provable Offline Reinforcement Learning: Neural Function Approximation, Randomization, and Sample Complexity 
    -- FPT AI, Vietnam, Dec. 21, 2022 

- Provable Offline Reinforcement Learning: Neural Function Approximation, Randomization, and Sample Complexity 
    -- UC San Diego, USA, Dec. 8, 2022 (Host: Rose Yu)

- Offline Reinforcement Learning: Assurance in High-Stakes AI Applications 
    -- IAA Research Summit, Johns Hopkins University, USA, Nov. 2022 

- Offline Neural Contextual Bandits: Pessimism, Optimization, and Generalization
    -- Ohio State University, USA, Jan. 2022 (Host: Yingbin Liang and Ness Shroff)

- Offline Neural Contextual Bandits: Pessimism, Optimization, and Generalization
    -- Arizona State University, USA, Dec. 2021 (Host: Kwang-Sung Jun)

- Generalization and Optimization in Deep Learning: Over-parameterization and Interpolation
    -- Deakin University, Australia, Aug. 2021 

- On Finite-Sample Analysis of Batch Reinforcement Learning with Deep ReLU Networks
    -- Viet Operator Theorists Group, Vietnam and USA, Apr. 2021


