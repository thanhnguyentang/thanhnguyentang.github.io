---
layout: post
title: Notes
---  
[[Back Home]](/)   

Maximum entropy sampler: Random notes on random topics (the topic mode is at approximate inference for generalization and robustness in RL and neural networks) for random thoughts. 

<!-- A collection of my notes drafted for various topics that I have investigated. I try the best to be self-contained when possible. A new blog post every week with probability of $1/3$. Most posts are in RL, Variational Inference and Information Theory with the goal in mind that they must be both *empirically* and *theoretically* insightful. Some are perspectives and insights about research per se.  -->

<!-- * 16/02/20: [A distributional perspective on learning.](/blogs/distributional) -->

* 12/04/20: [A Note on  Amortila et al. "A Distributional Analysis of Sampling-based RL Algorithms".](/blogs/distributional_analysis)
* 02/02/20: [Roadmap.](/blogs/read_map)
* 21/01/20: [Paradigm shift.](/blogs/paradigm_shift)
* 18/01/20: [My favourite quotes.](/blogs/quotes)
* 30/10/19: [Q-learning is provably efficient.](/blogs/q_learning_provable)
* 11/10/19: [A running note on measure theory.](/blogs/measure_theory)
* 20/09/19: [On patterned ways of thinking.](/blogs/rand_great)
* 18/08/19: [On some structures in the evolution of research idea in ML.](/blogs/paper_structures) (*LAST UPDATED: 14/04/20*)
* 08/08/19: [MDP basics.](/blogs/mdp)
<!-- * 06/08/19: [Concentration Inequalities.](/blogs/concentration_ineq) -->
* 05/08/19: [Actor-Critic Variants and Recursion-Preserving Principle for Incremental Learning.](/blogs/ac_variants)
* 03/08/19: [Wisdom in MLAI.](/blogs/wisdom) (*LAST UPDATED: 13/04/20*)
* 28/07/19: [Garner hype circle of your Ph.D.](/blogs/hype_circle)
* 22/07/19: [Lagrangian.](/blogs/lagrangian)
* 22/07/19: [Actor-Critic: Using relative returns to properly scale policy gradients.](/blogs/actor_critic) 
* 19/07/19: [From stochastic games to robustness in reinforcement learning.](/blogs/sgrl.pdf) (*presented at A2I2@Deakin*)
* 19/06/19: [A naive introduction to Optimal Transport.](/blogs/ot_intro) 
<!-- * 13/05/19: [Who to follow?](/blogs/who_to_follow)  -->
* 18/04/19: [How to write a first-class paper?](/blogs/how_to_write_papers) 
* 21/03/19: [A basic result of kernel embedding on probability space](/blogs/functional_prob_space)
* 20/03/19: [Basics of Reproducing Kernel Hilbert Space (RKHS).](/blogs/rkhs.pdf) 
<!-- * 08/08/18: [How Information theory possibly helps AI?](http://mlsidenotes.blogspot.com/2018/08/from-information-theory-to-machine.html) -->
* 17/06/18: [Gumbel-Softmax to Approximate Samples for a Categorical Distribution.](/blogs/gumbel_softmax) 
* 03/06/18: [Fundamental Elements of Gaussian Process.](/blogs/gp_fr.pdf) 
* 31/05/18: [Learning to Explain a Model via Variational Mutual Information, Jianbo Chen et al.](/blogs/l2x.pdf) (*presented at SAIL@UNIST*)   
* 22/05/18: [A Lazy Introduction to Reinforcement Learning: A Supervised Learning Perspective.](/blogs/rl_intro.pdf) 



<!-- ## Topics I plan to write on  
* <strike>Actor-critic algorithms in RL: done</strike> 
* Stabilizing and variance-reduction in Actor-Critic:
    * [Catastrophic forgetting and continual learning](https://arxiv.org/abs/1807.04015) 
    * [TD-regularized Actor-Critic methods](https://arxiv.org/abs/1812.08288) 
* Variational Inference in RL:
    * [Deep Variational RL for POMDPs](https://arxiv.org/abs/1806.02426)

* Invariant risk minimization  
* No free lunch theorem   -->
