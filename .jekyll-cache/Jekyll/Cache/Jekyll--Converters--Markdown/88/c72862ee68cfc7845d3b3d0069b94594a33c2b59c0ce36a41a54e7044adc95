I"¿<p><a href="/">[Back Home]</a>  <a href="/blogs/post">[Back to Blog]</a></p>

<h2 id="1-some-basics-of-measure-theory">1. Some basics of measure theory</h2>
<ul>
  <li>Pushforward measure</li>
  <li>$\mathcal{F}$-measurable</li>
  <li>Filtration</li>
  <li>Martingale</li>
  <li>Stopping time</li>
  <li>Martingale difference sequence</li>
</ul>

<h3 id="pushforward-measure">Pushforward measure</h3>

<p>Pushforward measure is a measure obtained by transforming a measure from one measurable space to another through a measurable mapping. Formally, consider two measurable spaces $(\Omega_1, \mathcal{F}_1)$ and $(\Omega_2, \mathcal{F}_2)$, $\mu: \mathcal{F}_1 \rightarrow \mathbb{R}^{+}$ is a measure on $\mathcal{F}_1$, $f: \Omega_1 \rightarrow \Omega_2$ is a measurable function. Then, the pushforward measure by $f$ on $\mu$ is given by</p>

\[(f_{\#} \mu)(A) := \mu(f^{-1}(A)), \forall A \in \mathcal{F}_2.\]

<p><strong>Change-of-variables formula</strong>:</p>

\[\int_{\Omega_2} g d(f_{\#} \mu) = \int_{\Omega_1} g \circ f d \mu.\]

<h3 id="mathcalf-measurable">$\mathcal{F}$-measurable</h3>
<p>Consider a probability space $(\Omega, \mathcal{F}, P)$, and a function $X: \Omega \rightarrow \mathbb{R}$. Then $X$ is said to be a $\mathcal{F}$-measurable if, informally speaking, the preimage of any measurable set via function $X$ is also measurable, or more formally, \(\{X \in A\} := X^{-1}(A) = \{ \omega \in \Omega | X(\omega) \in A\} \in \mathcal{F}, \forall A \in \mathcal{B}(\mathbb{R})\).</p>

<p>For any $X: \Omega \rightarrow \mathbb{R}$, $X$ is $\sigma(X)$-measurable by definition where 
\(\sigma(X) = \sigma(\{ X^{-1}(A) | A \in \mathcal{B}(\mathbb{R})\})\). Intuitively, $\sigma(X)$ is the smallest sigma algebra on which $X$ becomes measurable.</p>

<p>We can also define the $\sigma$-algebra generated by a set of random variables $(X_i)_{i \in I}$ as the $\sigma$-algebra of the union of the individual $\sigma$-algebras: \(\sigma(X_i, i \in I) = \sigma \left( \cup_{i \in I} \sigma(X_i) \right)\)</p>

<h3 id="filtration">Filtration</h3>
<p>A filtration is a increasing sequence of $\sigma$-algebras on a measureable space. Formally, given a measurable space $(\Omega, \mathcal{F})$, a filtration \((\mathcal{F}_t )_{t \geq 0}\) is a sequence of $\sigma$-algebras $\mathcal{F}_t \subseteq \mathcal{F}$  such that \(t_1 \leq t_2 \implies \mathcal{F}_{t_1} \subseteq \mathcal{F}_{t_2}\). Intuitively, when the index $t$ is the time index of a stochastic process, the filtration is usually used to describe all historial information about the stochastic process.</p>

<h3 id="martingale">Martingale</h3>
<p>A stochastic process \((X_t)_{t\geq 0}\) is said to be a martingale with respect to the filtration \((\mathcal{F}_t)_{t \geq 0}\) if:</p>
<ul>
  <li>$X_t$ is $\mathcal{F}_t$-measurable, (the sequence \((X_t, \mathcal{F}_t)_{t}\) is therefore said to be <strong>adapted</strong>)</li>
  <li>$\mathbb{E}  | X_t |  \leq \infty$, and</li>
  <li>$\mathbb{E}[ X_{t+1} | \mathcal{F}_t  ] = X_t $ a.s.</li>
</ul>

<p>for all $t$.</p>

<h3 id="stopping-time">Stopping time</h3>

<p>Give a probability space $(\Omega, \mathcal{F}, P)$ and filtration \((\mathcal{F}_t)_{t \in \mathbb{N}}\) of $\mathcal{F}$. A random variable \(T: \Omega \rightarrow \mathbb{N} \cup \{+\infty\}\) is said to be a stopping time if \(\{ T \leq t\} \in \mathcal{F}_t, \forall t \in \mathbb{N}\). A stopping time $T(\omega)$ is the first time a given event $\omega \in \Omega$ happens with the convention that $T(\omega) = +\infty$ if $\omega$ never happens.</p>

<h3 id="martingale-difference-sequence-mds">Martingale difference sequence (MDS)</h3>
<p>A martingale difference sequence (MDS) is a stochastic process whose expectation with respect to the past is zero. Formally, an adapted sequence \((X_t, \mathcal{F}_t)_{t}\) on $(\Omega, \mathcal{F}, P)$ is an MDS if $\mathbb{E} |X_t| &lt; \infty$ and $\mathbb{E}[X_t | \mathcal{F}_{t-1}] = 0$ for all $t$.</p>

<h2 id="2-common-concentration-inequalities">2. Common concentration inequalities</h2>
<ul>
  <li>Azuma-Hoeffding inequality</li>
  <li>Union bound</li>
</ul>

<h3 id="azuma-hoeffding-inequality">Azuma-Hoeffding Inequality</h3>

<p>Consider a MDS \((X_t)_t\) where \(a_t \leq X_t \leq b_t\) almost surely for some constant $a_t, b_t$ for all $t$. Then,</p>

\[P(\sum_{t=1}^n X_t &gt; \epsilon) \leq \exp \left(  \frac{-2 \epsilon ^2}{  \sum_{t=1}^n (b_t - a_t)^2 } \right),\]

<p>for all $\epsilon \geq 0$.</p>

<p>In other words, with probability at least $1 - \exp \left(  \frac{-2 \epsilon ^2}{  \sum_{t=1}^n (b_t - a_t)^2 } \right)$, we have \(\sum_{t=1}^n X_t \leq \epsilon.\)</p>

<h3 id="union-bound">Union bound</h3>
<p>Given a sequence of events $(A_t)_{t \in I}$ on a probability space $(\Omega, \mathcal{F}, P)$ where $A_t \in \mathcal{F}, \forall t$. Then we have 
\(P(A_t, \forall t \in I) \geq 1 - \sum_{t \in I} P(\bar{A}_t)\) where $\bar{A}_t = \Omega \backslash A_t$.</p>

<p>The following is a more concrete and commonly used result of a union bound. Assume that $\forall t \in I, P(a_t \leq X_t \leq b_t) \geq 1 - \delta / |I|$ for some constant $(a_t), (b_t)$ and $\delta$. Then it follows from a union bound that $P(a_t \leq X_t \leq b_t , \forall t \in I) \geq 1 - \delta$.</p>

<h2 id="3-bonus-a-list-of-probability-metrics">3. Bonus: A list of probability metrics</h2>

<ul>
  <li>Wasserstein distance</li>
  <li>MMD</li>
  <li>$\chi^2$-distance</li>
  <li>$\phi$-divergence</li>
  <li>Jensen-Shannon distance</li>
  <li>Jensen-Tsallis distance</li>
  <li>Cramer distance</li>
  <li>Stein discrepancy:</li>
</ul>

\[D(P,Q) = \max_{\phi \in \mathcal{F}} \mathbb{E}_{Q(x)}[trace(\mathcal{A}_P \phi(x))],\]

<p>where $\mathcal{A}_{P}(x) = \nabla_x \log P(x) \phi(x)^T + \nabla_x \phi(x)$</p>

<h2 id="references">References</h2>
<p>[1] Michael Kozdron, <a href="http://stat.math.uregina.ca/~kozdron/Teaching/Regina/862Winter06/Handouts/mart.pdf">http://stat.math.uregina.ca/~kozdron/Teaching/Regina/862Winter06/Handouts/mart.pdf</a> <br />
[2] <a href="https://math.stackexchange.com/a/508801/253451">https://math.stackexchange.com/a/508801/253451</a><br />
[3] Pradeep Ravikumar, <a href="http://www.cs.cmu.edu/~pradeepr/716/notes/lec7.pdf">http://www.cs.cmu.edu/~pradeepr/716/notes/lec7.pdf</a></p>

<p>(Work in progress, last update: 27/10/19)</p>
:ET