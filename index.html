<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Thanh Nguyen-Tang</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
<div id="layout-content">
</br>
 <h1>Thanh Nguyen-Tang</h1>
 <img alt="tnt" src="profile_pic.jpg"
style="display:inline;margin:5px 10px 0px 0px;float:center" width="163" id="profileimage">
<div id="subtitle">Postdoctoral Research Fellow <br />
<a href="https://www.cs.jhu.edu/" target=&ldquo;blank&rdquo;>Department of Computer Science</a> <br /> 
<a href="https://engineering.jhu.edu/" target=&ldquo;blank&rdquo;>Whiting School of Engineering</a> <br /> 
<a href="https://www.jhu.edu/" target=&ldquo;blank&rdquo;>Johns Hopkins University</a> <br /> <br />
Malone Hall 331, 3400 N Charles Street, Baltimore, MD 21218 <br /> <br /> 
<u>Email</u> <i>nguyent</i> at cs dot jhu dot edu / <i>thnguyentang</i> at gmail dot com <br /> <br />
<u>Profiles</u> <a href="https://scholar.google.com/citations?hl=en&amp;user=UrTlMiwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target=&ldquo;blank&rdquo;>Scholar</a>, 
<a href="https://github.com/thanhnguyentang" target=&ldquo;blank&rdquo;>Github</a>
</div>
<h2>About Me  </h2>
<p>I am a Postdoctoral Research Fellow in Department of Computer Science at Johns Hopkins University, 
working with <a href="https://www.cs.jhu.edu/~raman/Home.html" target=&ldquo;blank&rdquo;>Raman Arora</a>. I did a PhD in <a href="https://a2i2.deakin.edu.au/publications/" target=&ldquo;blank&rdquo;>the Applied AI Institute</a>, Deakin University (Australia) in 2022, and did my Master in Computer Science and Engineering at <a href="http://sailab.kaist.ac.kr/publications/" target=&ldquo;blank&rdquo;>the Statistical AI Lab</a>, Ulsan National Institute of Science and Technology (South Korea) in 2018. 
</p>
<h2>Research Interests </h2>
<p>I study the statistical and computational aspects of modern machine learning, with the focus on the following directions: 
</p>
<ul>
<li><p><b>Reinforcement learning</b>:  We develop new data-efficient algorithms that address emerging challenges of reinforcement learning and characterize the statistical and computational complexity of these algorithms. 
These include handling offline data, generalization across large state spaces, heterogeneous environments, multi-task representation learning and human feedback.   
</p>
</li>
<li><p><b>Stochastic optimization</b>: We study stochastic optimization problems that arise from modern data-driven machine learning applications.  
The studying aspect are characterizations of convergence rates, computational complexity, and robustness of these algorithms. 
Topics include zeroth-order optimization and adversarially/distributionally robust optimization.  
</p>
</li>
<li><p><b>Robust generalization</b>: We strive to develop new practical algorithms and theory for generalizing across different data distributions or robustifying against attacks. 
</p>
</li>
</ul>
<h2>Recent News   </h2>
<ul>
<li><p>02/27/2023: One paper accepted to CVPR&rsquo;23 (acceptance rate: 25.78%).  
</p>
</li>
<li><p>Jan. 20, 2023: One paper (top 25-percent noble) accepted to ICLR&rsquo;23 (acceptance rate: 31.8%).
</p>
</li>
<li><p>Dec. 9, 2022: One paper accepted to TMLR. 
</p>
</li>
<li><p>Nov. 19, 2022: One paper accepted to AAAI, 2023 (acceptance rate: 19.6%). 
</p>
</li>
<li><p>Oct. 30, 2022: I was acknowledged in Francis Bach's <a href="https://www.di.ens.fr/~fbach/ltfp_book.pdf" target=&ldquo;blank&rdquo;>&ldquo;Learning Theory from First Principles&rdquo;</a>.
</p>
</li>
<li><p>Sep. 14, 2022: One paper accepted to NeurIPS, 2022 (acceptance rate: 25.6%). 
</p>
</li>
<li><p>Jan. 21, 2022: One paper accepted to ICLR, 2022 (acceptance rate: 32.26%). 
</p>
</li>
<li><p>May 20, 2021: Accepted to the Deep Learning Theory Summer School at Princeton (acceptance rate: 180/500 = 36%).
</p>
</li>
</ul>
<h2>Publications  </h2>
<h3>2023 </h3>
<ul>
<li><p>A. Tuan Nguyen, <u>Thanh Nguyen-Tang</u>, Ser-Nam Lim, Philip Torr. <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Nguyen_TIPI_Test_Time_Adaptation_With_Transformation_Invariance_CVPR_2023_paper.html" target=&ldquo;blank&rdquo;>TIPI: Test Time Adaptation with Transformation Invariance</a>. IEEE/CVF Conference on Computer Vision and Pattern Recognition <font color=red >(CVPR)</font>, 2023.  
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Raman Arora. <a href="https://openreview.net/forum?id=WOquZTLCBO1" target=&ldquo;blank&rdquo;>VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation</a>.
International Conference on Learning Representations (<font color=red >ICLR</font>), 2023 (<font color=red >top 25% noble</font>)
[<a href="https://recorder-v3.slideslive.com/?share=80688&amp;s=a24d555f-edda-4210-a19e-4fded4165c62" target=&ldquo;blank&rdquo;>talk</a>] [<a href="assets/viper.pdf" target=&ldquo;blank&rdquo;>slides</a>] [<a href="https://github.com/thanhnguyentang/neural-offline-rl" target=&ldquo;blank&rdquo;>code</a>].  
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Ming Yin, Sunil Gupta, Svetha Venkatesh, Raman Arora. <a href="home">On Instance-Dependent Bounds for Offline Reinforcement Learning with Linear Function Approximation</a>.
AAAI Conference on Artificial Intelligence (<font color=red >AAAI</font>), 2023 [<a href="https://arxiv.org/abs/2211.13208" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="assets/aaai23-poster.pdf" target=&ldquo;blank&rdquo;>poster</a>] [<a href="assets/aaai23-slides-only.pdf" target=&ldquo;blank&rdquo;>slides</a>] [<a href="https://youtu.be/xUsMHodydO8" target=&ldquo;blank&rdquo;>video</a>].
</p>
</li>
</ul>
<h3>2022   </h3>
<ul>
<li><p><u>Thanh Nguyen-Tang</u>, Sunil Gupta, Hung Tran-The, Svetha Venkatesh. <a href="https://openreview.net/forum?id=LdEm0umNcv" target=&ldquo;blank&rdquo;>On Sample Complexity of Offline Reinforcement Learning with Deep ReLU Networks in Besov Spaces</a>. 
Transactions on Machine Learning Research (<font color=red >TMLR</font>), 2022.  
</p>
</li>
<li><p>Ragja Palakkadavath, <u>Thanh Nguyen-Tang</u>, Sunil Gupta, Svetha Venkatesh. <a href="https://openreview.net/pdf?id=Yl_4LpR_3Z" target=&ldquo;blank&rdquo;>Improving Domain Generalization with Interpolation Robustness</a>. 
Distribution Shifts Workshop@NeurIPS, INTERPOLATE@NeurIPS (<font color=red >Spotlight</font>), 2022.  
</p>
</li>
<li><p>Anh Tong, <u>Thanh Nguyen-Tang</u>, Toan Tran, Jaesik Choi. <a href="https://openreview.net/pdf?id=lTZBRxm2q5" target=&ldquo;blank&rdquo;>Learning Fractional White Noises in Neural Stochastic Differential Equations</a>.
Advances in Neural Information Processing Systems (<font color=red >NeurIPS</font>), 2022. 
[<a href="https://github.com/anh-tong/fractional_neural_sde" target=&ldquo;blank&rdquo;>code</a>].  
</p>
</li>
<li><p>Mengyan Zhang, <u>Thanh Nguyen-Tang</u>, Fangzhao Wu, Zhenyu He, Xing Xie, Cheng Soon Ong. 
<a href="home">Two-Stage Neural Contextual Bandits for Adaptive Personalised Recommendation</a>. Preprint, 2022.  
[<a href="https://arxiv.org/abs/2206.14648" target=&ldquo;blank&rdquo;>arXiv</a>].  
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Sunil Gupta, A.Tuan Nguyen, and Svetha Venkatesh. 
<a href="https://openreview.net/pdf?id=sPIFuucA3F" target=&ldquo;blank&rdquo;>Offline Neural Contextual Bandits:  Pessimism, Optimization and Generalization</a>.
International Conference on Learning Representations (<font color=red >ICLR</font>), 2022. 
[<a href="https://arxiv.org/abs/2111.13807" target=&ldquo;blank&rdquo;>arXiv</a>] 
[<a href="assets/poster_NeurIPSW21.pdf" target=&ldquo;blank&rdquo;>poster</a>]  
[<a href="assets/neuralcb_slides.pdf" target=&ldquo;blank&rdquo;>slides</a>] 
[<a href="https://github.com/thanhnguyentang/offline_neural_bandits" target=&ldquo;blank&rdquo;>code</a>].  
</p>
</li>
</ul>
<h3>2021</h3>
<ul>
<li><p><u>Thanh Nguyen-Tang</u>, Sunil Gupta, Hung Tran-The, Svetha Venkatesh.
<a href="https://lyang36.github.io/icml2021_rltheory/camera_ready/5.pdf" target=&ldquo;blank&rdquo;>Sample Complexity of Offline Reinforcement Learning with Deep ReLU Networks</a>. 
Workshop on RL Theory, ICML, 2021. [<a href="https://arxiv.org/abs/2103.06671" target=&ldquo;blank&rdquo;>arXiv</a>]
[<a href="https://thanhnguyentang.github.io/assets/offrelu.pdf" target=&ldquo;blank&rdquo;>slides</a>] 
[<a href="https://www.youtube.com/watch?v=xLM5pondWY4" target=&ldquo;blank&rdquo;>talk</a>].  
</p>
</li>
<li><p><u>Thanh Nguyen-Tang</u>, Sunil Gupta, Svetha Venkatesh. 
<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17104" target=&ldquo;blank&rdquo;>Distributional Reinforcement Learning via Moment Matching</a>. 
AAAI Conference on Artificial Intelligence (<font color=red >AAAI</font>), 2021. 
[<a href="http://arxiv.org/abs/2007.12354" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://github.com/thanhnguyentang/mmdrl" target=&ldquo;blank&rdquo;>code</a>]
[<a href="https://cutt.ly/fkkiAGm" target=&ldquo;blank&rdquo;>slides</a>] 
[<a href="https://cutt.ly/4kkiJZt" target=&ldquo;blank&rdquo;>poster</a>] [<a href="https://youtu.be/1fMqZZjy84E" target=&ldquo;blank&rdquo;>talk</a>].  
</p>
</li>
</ul>
<h3>2020</h3>
<ul>
<li><p><u>Thanh Nguyen-Tang</u>, Sunil Gupta, Huong Ha, Santu Rana, Svetha Venkatesh. 
<a href="http://proceedings.mlr.press/v108/nguyen20a.html" target=&ldquo;blank&rdquo;>Distributionally Robust Bayesian Quadrature Optimization</a>. 
International Conference on Artificial Intelligence and Statistics (<font color=red >AISTATS</font>), 2020. 
[<a href="https://arxiv.org/abs/2001.06814" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://github.com/thanhnguyentang/drbqo" target=&ldquo;blank&rdquo;>code</a>]
[<a href="https://thanhnguyentang.github.io/assets/aistats20_drbqo.pdf" target=&ldquo;blank&rdquo;>slides</a>] 
[<a href="https://slideslive.com/38930124/" target=&ldquo;blank&rdquo;>talk</a>].  
</p>
</li>
</ul>
<h3>2019</h3>
<ul>
<li><p><u>Thanh Nguyen-Tang</u>, Jaesik Choi. 
<a href="https://doi.org/10.3390/e21100976" target=&ldquo;blank&rdquo;>Markov Information Bottleneck to Improve Information Flow in Stochastic Neural Networks</a>. <font color=red >Entropy</font>, 2019 (Special Issue on Information Bottleneck: Theory and Applications in Deep Learning). 
</p>
</li>
<li><p>Huong Ha, Santu Rana, Sunil Gupta, <u>Thanh Nguyen-Tang</u>, Hung Tran-The, Svetha Venkatesh.
<a href="https://papers.nips.cc/paper/9350-bayesian-optimization-with-unknown-search-space" target=&ldquo;blank&rdquo;>Bayesian Optimization with Unknown Search Space</a>.
Advances in Neural Information Processing Systems (<font color=red >NeurIPS</font>), 2019.
[<a href="https://github.com/HuongHa12/BO_unknown_searchspace" target=&ldquo;blank&rdquo;>code</a>]
[<a href="https://postersession.ai/poster/bayesian-optimization-with-unknown-searc/" target=&ldquo;blank&rdquo;>poster</a>].  
</p>
</li>
</ul>
<h2>Academic Service  </h2>
<ul>
<li><p>Senior program committee: AAAI (2023, 2024).
</p>
</li>
<li><p>Conference reviewer/program committee: NeurIPS (2023, 2022, 2021, 2020), ICML (2023, 2022, 2021), 
ICLR (2023, 2022, 2021- outstanding reviewer award), 
AAAI (2022, 2021-<a href="https://aaai.org/Conferences/AAAI-21/wp-content/uploads/2021/05/AAAI-21-Program-Committee.pdf" target=&ldquo;blank&rdquo;>Top 25% PC</a>, 2020), AISTATS (2021), L4DC (2022). 
</p>
</li>
<li><p>Workshop reviewer/program committee: EWRL (2022), NeurIPS Workshop on OfflineRL (2022, 2021), ICML&rsquo;23 Workshop on Interactive Learning with Implicit Human Feedback.
</p>
</li>
<li><p>Journal reviewer: TPAMI. 
</p>
</li>
<li><p>Volunteer: AAAI (2023 - session chair for ML theory), ICML (2022), AutoML (2022).   
</p>
</li>
</ul>
<h2>Teaching </h2>
<ul>
<li><p>Guest lecturer (in bandits/reinforcement learning): Machine Learning (CS 475/675) Spring 2023, JHU. 
</p>
</li>
</ul>
<h2>Invited Talks </h2>
<ul>
<li><p>VinAI, Vietnam, Jan. 13, 2023 [<a href="https://www.vinai.io/seminar-posts/provable-offline-reinforcement-learning-neural-function-approximation-randomization-and-sample-complexity/" target=&ldquo;blank&rdquo;>post</a>].
</p>
</li>
<li><p>FPT AI, Vietnam, Dec. 21, 2022 [<a href="https://www.youtube.com/watch?v=FNj8UScJmrk" target=&ldquo;blank&rdquo;>record</a>].
</p>
</li>
<li><p>UC San Diego, USA, Dec. 8, 2022 (Host: <a href="https://roseyu.com/" target=&ldquo;blank&rdquo;>Rose Yu</a>).
</p>
</li>
<li><p>IAA Research Summit, Johns Hopkins University, USA, Nov. 2022 [<a href="assets/offrl_iaa_22.pdf" target=&ldquo;blank&rdquo;>slides</a>].
</p>
</li>
<li><p>Ohio State University, USA, Jan. 2022 (Host: <a href="https://sites.google.com/view/yingbinliang/home" target=&ldquo;blank&rdquo;>Yingbin Liang</a> and <a href="http://newslab.ece.ohio-state.edu/home/" target=&ldquo;blank&rdquo;>Ness Shroff</a>).
</p>
</li>
<li><p>Arizona State University, USA, Dec. 2021 (Host: <a href="https://kwangsungjun.github.io/" target=&ldquo;blank&rdquo;>Kwang-Sung Jun</a>).
</p>
</li>
<li><p>Virginia Tech, USA, Nov. 2021 (Host: <a href="https://sites.google.com/site/thinhdoan210/home" target=&ldquo;blank&rdquo;>Thinh T. Doan</a>).
</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2023-06-06 22:47:52 EDT, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
(<a href="index.jemdoc">source</a>)
</div>
</div>
</div>
</body>
</html>
