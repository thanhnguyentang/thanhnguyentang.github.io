<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Thanh Nguyen-Tang</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div id="profile">
<img alt="tnt" src="profile_pic.jpg"
style="display:inline;margin:5px 10px 0px 0px;float:center" width="120">
</div>
<hr>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="blog.html">Blog</a></div>
<div class="menu-item"><a href="news.html">News&nbsp;and&nbsp;Events</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="projects.html">Projects</a></div>
<div class="menu-item"><a href="collaborators.html">Collaborators</a></div>
<div class="menu-item"><a href="photos.html">Photos</a></div>
<div class="menu-item"><a href="resources.html">Resources</a></div>
<hr>
<div id="counter">
  <script type='text/javascript'
    id='clustrmaps'
    src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=120&t=tt&d=82NHafzempW8zXlKpsMbUtpsRrG-yvVYFzxInVdWKuQ'>
    </script>
</div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Thanh Nguyen-Tang</h1>
<div id="subtitle">Associate Research Fellow <br />
<a href="https://a2i2.deakin.edu.au/" target=&ldquo;blank&rdquo;>Applied AI Institute (A\(^2\)I\(^2\))</a> <br /> 
Deakin University, Australia <br /> 
Email: <i>nguyent2792</i> [AT] gmail [DOT] com 
</div>
</div>
<p><b>Intro.</b> I am currently an Associate Research Fellow and have recently finished my PhD (Feb 2022) at the Applied AI Institute, Deakin University. 
Prior to that, I was a researcher at Ulsan National University of Science and Technology (UNIST) from Mar 2018 to Dec 2018, 
and I obtained my Master at UNIST in 2018. I was also serving as a ML technical consultant for a local startup company on NLP product solutions. 
<br />
</p>
<p><b>Research interests.</b> Algorithmic and theoretical foundations of modern machine learning - reinforcement learning, deep learning and representation learning. 
</p>
<p>We are running a mini <a href="mslos.html" target=&ldquo;blank&rdquo;>Modern Statistical Learning and Optimization Seminar (MSLOS)</a>.
</p>
<p>I’m always actively open to research collaborations and chat!
</p>
<p>Here are my 
<a href="https://scholar.google.com/citations?hl=en&amp;user=UrTlMiwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target=&ldquo;blank&rdquo;>Google Scholar</a>, 
<a href="https://www.semanticscholar.org/author/Thanh-Nguyen-Tang/1490490191?sort=pub-date" target=&ldquo;blank&rdquo;>Semantic Scholar</a>, 
<a href="https://github.com/thanhnguyentang" target=&ldquo;blank&rdquo;>Github</a>,
<a href="https://twitter.com/thanhnguyentang" target=&ldquo;blank&rdquo;>Twitter</a> . 
</p>
<h2>Latest News </h2>
<ul>
<li><p>[Jan 21, 2022] One paper got accepted to ICLR, 2022. 
</p>
</li>
<li><p>[Oct 25, 2021] A short version of our work has been accepted to the NeurIPS&rsquo;21 Workshop on Offline Reinforcement Learning.
</p>
</li>
<li><p>[Jul 8, 2021] A short version of our work has been accepted to the ICML&rsquo;21 Workshop on Reinforcement Learning Theory.
</p>
</li>
<li><p>[Jul 1, 2021] I start my postdoc at A\(^2\)I\(^2\), Deakin University after submitting my Ph.D. thesis in 24 Jun. 
</p>
</li>
<li><p>[May 20, 2021] I have been accepted to the Deep Learning Theory Summer School at Princeton, acceptance rate: 180/500 = 36%.
</p>
</li>
</ul>
<h2>Publications  </h2>
<h3><b></b>2022<b></b> </h3>
<ul>
<li><p><a href="https://thanhnguyentang.github.io/" target=&ldquo;blank&rdquo;><b>Learning White Noises in Neural Stochastic Differential Equations</b></a><br />  
Anh Tong, <b>Thanh Nguyen-Tang</b>, Toan Tran, Jaesik Choi <br />
Under review, 2022 <br />
</p>
</li>
<li><p><a href="https://thanhnguyentang.github.io/" target=&ldquo;blank&rdquo;><b>Two-Stage Neural Contextual Bandits for Personalised News Recommendation</b></a><br />  
Mengyan Zhang, <b>Thanh Nguyen-Tang</b>, Fangzhao Wu, Zhenyu He, Xing Xie, Cheng Soon Ong <br />
Under review, 2022 <br />
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2107.11533" target=&ldquo;blank&rdquo;><b>Partially Offline Contextual Bandit Learning under Support Defficiency</b></a><br />
Hung Tran-The, <b>Thanh Nguyen-Tang</b>, Sunil Gupta, Santu Rana, Svetha Venkatesh <br /> 
Under review, 2022 <br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://openreview.net/pdf?id=sPIFuucA3F" target=&ldquo;blank&rdquo;><b>Offline Neural Contextual Bandits:  Pessimism, Optimization and Generalization</b></a><br />
<b>Thanh Nguyen-Tang</b>, Sunil Gupta, A.Tuan Nguyen, and Svetha Venkatesh <br />  
ICLR, 2022 <br /> 
<a href="https://offline-rl-neurips.github.io/2021/pdf/28.pdf" target=&ldquo;blank&rdquo;>Workshop on Offline Reinforcement Learning</a>, NeurIPS, 2021 <br /> 
[<a href="https://arxiv.org/abs/2111.13807" target=&ldquo;blank&rdquo;>arXiv</a>] 
[<a href="assets/poster_NeurIPSW21.pdf" target=&ldquo;blank&rdquo;>Poster</a>]  
[<a href="assets/neuralcb_slides.pdf" target=&ldquo;blank&rdquo;>Slides</a>] 
[<a href="https://github.com/thanhnguyentang/offline_neural_bandits" target=&ldquo;blank&rdquo;>Code</a>]
</p>
</li>
</ul>
<h3><b></b>2021<b></b> </h3>
<ul>
<li><p><a href="https://lyang36.github.io/icml2021_rltheory/camera_ready/5.pdf" target=&ldquo;blank&rdquo;><b>Sample Complexity of Offline Reinforcement Learning with Deep ReLU Networks</b></a> <br />
<b>Thanh Nguyen-Tang</b>, Sunil Gupta, Hung Tran-The, Svetha Venkatesh <br />
Workshop on Reinforcement Learning Theory, ICML, 2021 <br />
[<a href="https://arxiv.org/abs/2103.06671" target=&ldquo;blank&rdquo;>arXiv</a>]
[<a href="https://thanhnguyentang.github.io/assets/offrelu.pdf" target=&ldquo;blank&rdquo;>Slides</a>] 
[<a href="https://www.youtube.com/watch?v=xLM5pondWY4" target=&ldquo;blank&rdquo;>Talk</a>]
</p>
</li>
<li><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/17104" target=&ldquo;blank&rdquo;><b>Distributional Reinforcement Learning via Moment Matching</b></a><br /> 
<b>Thanh Nguyen-Tang</b>, Sunil Gupta, Svetha Venkatesh <br /> 
AAAI, 2021 <br />
[<a href="http://arxiv.org/abs/2007.12354" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://github.com/thanhnguyentang/mmdrl" target=&ldquo;blank&rdquo;>Code</a>]
[<a href="https://cutt.ly/fkkiAGm" target=&ldquo;blank&rdquo;>Slides</a>] 
[<a href="https://cutt.ly/4kkiJZt" target=&ldquo;blank&rdquo;>Poster</a>] [<a href="https://youtu.be/1fMqZZjy84E" target=&ldquo;blank&rdquo;>Talk</a>] 
</p>
</li>
</ul>
<h3><b></b>2020<b></b></h3>
<ul>
<li><p><a href="http://proceedings.mlr.press/v108/nguyen20a.html" target=&ldquo;blank&rdquo;><b>Distributionally Robust Bayesian Quadrature Optimization</b></a><br /> 
<b>Thanh Tang Nguyen</b>, Sunil Gupta, Huong Ha, Santu Rana, Svetha Venkatesh<br /> 
AISTATS, 2020 <br /> 
[<a href="https://arxiv.org/abs/2001.06814" target=&ldquo;blank&rdquo;>arXiv</a>] [<a href="https://github.com/thanhnguyentang/drbqo" target=&ldquo;blank&rdquo;>Code</a>]
[<a href="https://thanhnguyentang.github.io/assets/aistats20_drbqo.pdf" target=&ldquo;blank&rdquo;>Slides</a>] 
[<a href="https://slideslive.com/38930124/" target=&ldquo;blank&rdquo;>Talk</a>]  
</p>
</li>
</ul>
<h3><b></b>2019<b></b> </h3>
<ul>
<li><p><a href="https://doi.org/10.3390/e21100976" target=&ldquo;blank&rdquo;><b>Markov Information Bottleneck to Improve Information Flow in Stochastic Neural Networks</b></a><br />
<b>Thanh Tang Nguyen</b>, Jaesik Choi<br />
Entropy, 21(10), 976, 2019 <br /> 
[<a href="https://github.com/thanhnguyentang/pib" target=&ldquo;blank&rdquo;>Code</a>]
</p>
</li>
<li><p><a href="https://papers.nips.cc/paper/9350-bayesian-optimization-with-unknown-search-space" target=&ldquo;blank&rdquo;><b>Bayesian Optimization with Unknown Search Space</b></a><br />
Huong Ha, Santu Rana, Sunil Gupta, <b>Thanh Tang Nguyen</b>, Hung Tran-The, Svetha Venkatesh <br />
NeurIPS, 2019 <br />
[<a href="https://github.com/HuongHa12/BO_unknown_searchspace" target=&ldquo;blank&rdquo;>Code</a>]
[<a href="https://postersession.ai/poster/bayesian-optimization-with-unknown-searc/" target=&ldquo;blank&rdquo;>Poster</a>]
</p>
</li>
</ul>
<h3>Dissertations </h3>
<ul>
<li><p><a href="https://thanhnguyentang.github.io/" target=&ldquo;blank&rdquo;><b>On Practical Reinforcement Learning: Provable Robustness, Scalability and Statistical Efficiency</b></a><br /> 
Ph.D. dissertation, Deakin University, Australia, July 2021
</p>
</li>
</ul>
<ul>
<li><p><a href="http://scholarworks.unist.ac.kr/handle/201301/23561" target=&ldquo;blank&rdquo;><b>Parametric Information Bottleneck to Optimize Stochastic Neural Networks</b></a><br />
Master Thesis, Ulsan National University of Science and Technology, South Korea, 2018<br />
[<a href="https://thanhnguyentang.github.io/assets/PIB_thesis_slide.pdf" target=&ldquo;blank&rdquo;>Slides</a>] [<a href="https://www.youtube.com/watch?v=md9qV4Hrgbo&amp;t=378s" target=&ldquo;blank&rdquo;>Talk</a>]
</p>
</li>
</ul>
<h2>Supervision and mentoring </h2>
<ul>
<li><p><a href="https://scholar.google.com/citations?user=cVTpiuoAAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>Ragja Palakkadavath</a> &ndash; Ph.D. student at A2I2, Deakin University – Topic: Domain Generalization    
</p>
</li>
<li><p>Nguyen Ngoc Hieu &ndash; Resident at FPT.AI &ndash; Topic: Learning Theory for Implicit Deep Models. 
</p>
</li>
<li><p><a href="https://qiyaowei.github.io/index.html" target=&ldquo;blank&rdquo;>Qiyao Wei</a>, senior undergrad at University of Toronto – Topic: Research statement in offline RL for PhD application   
</p>
</li>
</ul>
<h2>Academic Service  </h2>
<ul>
<li><p>Reviewer, NeurIPS, 2022  
</p>
</li>
<li><p>Program Committee, EWRL, 2022  
</p>
</li>
<li><p>Reviewer, L4DC, 2022 (1 paper)
</p>
</li>
<li><p>Reviewer, ICML, 2022  (3 papers)
</p>
</li>
<li><p>Program Committee, NeurIPS Workshop on Offline Reinforcement Learning, 2021 
</p>
</li>
<li><p>Program Committee, AAAI, 2022 
</p>
</li>
<li><p>Reviewer, ICLR, 2022 
</p>
</li>
<li><p>Reviewer, NeurIPS, 2021 
</p>
</li>
<li><p>Reviewer, ICML, 2021 
</p>
</li>
<li><p>Reviewer, AISTATS, 2021 
</p>
</li>
<li><p>Program Committee, AAAI, 2021 
</p>
</li>
<li><p>Reviewer, ICLR, 2021 (<b>outstanding reviewer award</b>)
</p>
</li>
<li><p>Reviewer, NeurIPS, 2020 
</p>
</li>
</ul>
<p>I created the <a href="https://thanhnguyentang.github.io/mlten.html" target=&ldquo;blank&rdquo;>&ldquo;ML Theory Exchange Network&rdquo; Discord channel</a> (currently 66 members as of 25 Oct 2021) 
to connect ML-theory passionate self-learners (like myself) with senior researchers for exchanging ideas and learning resources. </p>
<div id="footer">
<div id="footer-text">
Page generated 2022-05-21 11:47:03 +07, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
(<a href="index.jemdoc">source</a>)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
