---
layout: post
title: A running note on measure theory
---  
[[Back Home]](/)  [[Back to Blog]](/blogs/post) 

## Pushforward measure  
Pushforward measure is a measure obtained by transforming a measure from one measurable space to another through a measurable mapping. Formally, consider two measurable spaces $(\Omega_1, \mathcal{F}_1)$ and $(\Omega_2, \mathcal{F}_2)$, $\mu: \mathcal{F}_1 \rightarrow \mathbb{R}^{+}$ is a measure on $\mathcal{F}_1$, $f: \Omega_1 \rightarrow \Omega_2$ is a measurable function. Then, the pushforward measure by $f$ on $\mu$ is given by

$$
(f_{\#} \mu)(A) := \mu(f^{-1}(A)), \forall A \in \mathcal{F}_2.
$$

**Change-of-variables formula**: 

$$
\int_{\Omega_2} g d(f_{\#} \mu) = \int_{\Omega_1} g \circ f d \mu.
$$


## $\mathcal{F}$-measurable    
Consider a probability space $(\Omega, \mathcal{F}, P)$, and a function $X: \Omega \rightarrow \mathbb{R}$. Then $X$ is said to be a $\mathcal{F}$-measurable if, informally speaking, the preimage of any measurable set via function $X$ is also measurable, or more formally, $$\{X \in A\} := X^{-1}(A) = \{ \omega \in \Omega | X(\omega) \in A\} \in \mathcal{F}, \forall A \in \mathcal{B}(\mathbb{R})$$.

For any $X: \Omega \rightarrow \mathbb{R}$, $X$ is $\sigma(X)$-measurable by definition where 
$$\sigma(X) = \sigma(\{ X^{-1}(A) | A \in \mathcal{B}(\mathbb{R})\})$$. Intuitively, $\sigma(X)$ is the smallest sigma algebra on which $X$ becomes measurable. 

We can also define the $\sigma$-algebra generated by a set of random variables $(X_i)_{i \in I}$ as the $\sigma$-algebra of the union of the individual $\sigma$-algebras: $$\sigma(X_i, i \in I) = \sigma \left( \cup_{i \in I} \sigma(X_i) \right)$$


## Filtration   
A filtration is a increasing sequence of $\sigma$-algebras on a measureable space. Formally, given a measurable space $(\Omega, \mathcal{F})$, a filtration $$(\mathcal{F}_t )_{t \geq 0}$$ is a sequence of $\sigma$-algebras $\mathcal{F}_t \subseteq \mathcal{F}$  such that $$t_1 \leq t_2 \implies \mathcal{F}_{t_1} \subseteq \mathcal{F}_{t_2}$$. Intuitively, when the index $t$ is the time index of a stochastic process, the filtration is usually used to describe all historial information about the stochastic process.   


## Martingale   
A stochastic process $$(X_t)_{t\geq 0}$$ is said to be a martingale with respect to the filtration $$(\mathcal{F}_t)_{t \geq 0}$$ if: 
* $X_t$ is $\mathcal{F}_t$-measurable, (the sequence $$(X_t, \mathcal{F}_t)_{t}$$ is therefore said to be **adapted**)
* $\mathbb{E}  \| X_t \|  \leq \infty$, and
* $\mathbb{E}[ X_{t+1} \| \mathcal{F}_t  ] = X_t $ a.s.    

for all $t$. 

## Stopping time  

Give a probability space $(\Omega, \mathcal{F}, P)$ and filtration $$(\mathcal{F}_t)_{t \in \mathbb{N}}$$ of $\mathcal{F}$. A random variable $$T: \Omega \rightarrow \mathbb{N} \cup \{+\infty\}$$ is said to be a stopping time if $$\{ T \leq t\} \in \mathcal{F}_t, \forall t \in \mathbb{N}$$. A stopping time $T(\omega)$ is the first time a given event $\omega \in \Omega$ happens with the convention that $T(\omega) = +\infty$ if $\omega$ never happens. 

## Martingale difference sequence (MDS)  
A martingale difference sequence (MDS) is a stochastic process whose expectation with respect to the past is zero. Formally, an adapted sequence $$(X_t, \mathcal{F}_t)_{t}$$ on $(\Omega, \mathcal{F}, P)$ is an MDS if $\mathbb{E} \|X_t\| < \infty$ and $\mathbb{E}[X_t \| \mathcal{F}_{t-1}] = 0$ for all $t$. 


## Azuma-Hoeffding Inequality  

Consider a MDS $$(X_t)_t$$ where $$a_t \leq X_t \leq a_t$$ almost surely for some constant $a_t, b_t$ for all $t$. Then, 

$$ P(\sum_{t=1}^n X_t > \epsilon) \leq \exp \left(  \frac{-2 \epsilon ^2}{  \sum_{t=1}^n (b_t - a_t)^2 } \right), $$

for all $\epsilon \geq 0$.

## Bonus: A list of probability metrics  

* Wasserstein distance 
* MMD 
* $\chi^2$-distance 
* $\phi$-divergence 
* Jensen-Shannon distance 
* Jensen-Tsallis distance
* Cramer distance 
* Stein discrepancy: 

$$
D(P,Q) = \max_{\phi \in \mathcal{F}} \mathbb{E}_{Q(x)}[trace(\mathcal{A}_P \phi(x))],
$$  

where $\mathcal{A}_{P}(x) = \nabla_x \log P(x) \phi(x)^T + \nabla_x \phi(x)$


## References  
[1] Michael Kozdron, [http://stat.math.uregina.ca/~kozdron/Teaching/Regina/862Winter06/Handouts/mart.pdf](http://stat.math.uregina.ca/~kozdron/Teaching/Regina/862Winter06/Handouts/mart.pdf)   
[2] [https://math.stackexchange.com/a/508801/253451](https://math.stackexchange.com/a/508801/253451)  
[3] Pradeep Ravikumar, [http://www.cs.cmu.edu/~pradeepr/716/notes/lec7.pdf](http://www.cs.cmu.edu/~pradeepr/716/notes/lec7.pdf)  

(Work in progress, last update: 27/10/19)